{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# from src.utils.data_utils import TGIF\n",
    "from src.utils.data_utils import MMNist\n",
    "from src.utils.gan_trainer import ModelTrainer\n",
    "from src.utils.initializer import Initializer\n",
    "\n",
    "from src.models.latent_lstm_vaegan import LatentLSTM\n",
    "from src.models.vaegan import VAEGAN_Disc, Initializer\n",
    "\n",
    "from src.utils.vis_utils import *\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "TEST_MODEL_PATH = os.path.join(os.getcwd(), 'src', 'experiments', 'latent-lstm-gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using type: torch.float32\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using device:', device)\n",
    "print('Using type:', dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SZ = (64, 64)\n",
    "MAX_FRAMES = 10\n",
    "DATASET_ROOT = '/home/deepdeepfakes/cs231n-project/src/datasets/MMNIST'\n",
    "TRANSFORMS = transforms.Compose([\n",
    "#                         transforms.Resize(IMAGE_SZ),                   \n",
    "                        transforms.ToTensor()\n",
    "                        ])\n",
    "\n",
    "train_set = MMNist(f'{DATASET_ROOT}/train_set.npz', temporality=True, transform=TRANSFORMS)\n",
    "val_set = MMNist(f'{DATASET_ROOT}/val_set.npz', temporality=True, transform=TRANSFORMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 10000\n"
     ]
    }
   ],
   "source": [
    "BATCH_SZ = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SZ, shuffle=True, drop_last=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SZ, shuffle=True, drop_last=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(len(train_set), len(val_set)) #, len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# dataiter = iter(train_loader)\n",
    "# gif = dataiter.next()[0]\n",
    "    \n",
    "# imshow(torchvision.utils.make_grid(gif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DISP_LIM = 16\n",
    "\n",
    "def rescale(x):\n",
    "    low, high = x.min(), x.max()\n",
    "    x_rescaled = (x - low) / (high - low)\n",
    "    return x_rescaled\n",
    "\n",
    "\n",
    "def make_gif(model, seed_frame, curr_h=None, gif_length=20):\n",
    "    if not curr_h:\n",
    "        curr_h = model.init_hidden(BATCH_SZ)\n",
    "        \n",
    "    curr_x = seed_frame.to(device=device, dtype=dtype)\n",
    "    ret = [seed_frame]\n",
    "    \n",
    "    for i in range(gif_length - 1): \n",
    "        y, curr_h = model(curr_x, curr_h)\n",
    "        curr_x = y\n",
    "        ret.append(y.to(device = torch.device('cpu')))\n",
    "    \n",
    "    return torch.stack(ret).transpose(0, 1).squeeze()\n",
    "\n",
    "def test_lstm_eval(model, loader):\n",
    "    model.eval()\n",
    "    dataiter = iter(loader)\n",
    "    x = dataiter.next()\n",
    "    \n",
    "    seeds = x[:, 0, :, :, :]\n",
    "    seeds = seeds.unsqueeze(1)\n",
    "    gif = make_gif(model, seeds)\n",
    "    \n",
    "    orig_gifs = torch.cat(tuple(x))[:DISP_LIM]\n",
    "    out_gifs = torch.cat(tuple(gif))[:DISP_LIM]\n",
    "    out_gifs = out_gifs.clamp(0, 1).unsqueeze(1)\n",
    "    \n",
    "    img_show(torchvision.utils.make_grid(orig_gifs))\n",
    "    img_show(torchvision.utils.make_grid(out_gifs.detach()))\n",
    "\n",
    "    \n",
    "def first_frame_hidden_state(model, first_seeds):\n",
    "    curr_h = model.init_hidden(BATCH_SZ)\n",
    "    curr_x = first_seeds.to(device=device, dtype=dtype)\n",
    "    \n",
    "    _, curr_h = model(curr_x, curr_h)\n",
    "    \n",
    "    return curr_h\n",
    "\n",
    "\n",
    "    \n",
    "def test_lstm_eval_2(model, loader):\n",
    "    model.eval()\n",
    "    dataiter = iter(loader)\n",
    "    x = dataiter.next()\n",
    "    \n",
    "    throwaway_seeds = x[:, 0, :, :, :]\n",
    "    throwaway_seeds = throwaway_seeds.unsqueeze(1)\n",
    "    \n",
    "    curr_h = first_frame_hidden_state(model, throwaway_seeds)    \n",
    "    \n",
    "    \n",
    "    seeds = x[:, 1, :, :, :]\n",
    "    seeds = seeds.unsqueeze(1)\n",
    "    gif = make_gif(model, seeds, curr_h=curr_h)\n",
    "    \n",
    "    orig_gifs = torch.cat(tuple(x))[:DISP_LIM]\n",
    "    out_gifs = torch.cat(tuple(gif))[:DISP_LIM]\n",
    "    out_gifs = out_gifs.clamp(0, 1).unsqueeze(1)\n",
    "    \n",
    "    img_show(torchvision.utils.make_grid(orig_gifs))\n",
    "    img_show(torchvision.utils.make_grid(out_gifs.detach()))    \n",
    "    \n",
    "    \n",
    "def test_lstm_train(model, loader):\n",
    "    model.train()\n",
    "    dataiter = iter(loader)\n",
    "    x = dataiter.next()\n",
    "    x = x.to(device=device)\n",
    "    \n",
    "    orig_gifs = torch.cat(tuple(x))[:DISP_LIM]\n",
    "    orig_gifs = orig_gifs.cpu().detach()\n",
    "    \n",
    "    out_gifs, hidden_out = model(x, model.init_hidden(BATCH_SZ))\n",
    "    out_gifs = out_gifs[0]\n",
    "    out_gifs = out_gifs.clamp(0, 1)\n",
    "    out_gifs = out_gifs.cpu().detach()[:DISP_LIM]  \n",
    "    \n",
    "    img_show(torchvision.utils.make_grid(orig_gifs))\n",
    "    img_show(torchvision.utils.make_grid(out_gifs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(gen_model, disc_model, gen_optimizer, disc_optimizer, x):\n",
    "    \n",
    "    N, T, C, H, W = x.shape\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss(size_average=True)\n",
    "    gan_reg = 3e-4\n",
    "    kl_reg = 1e-8\n",
    "    disc_err_fake_reg = 1\n",
    "    \n",
    "    h0 = gen_model.init_hidden(BATCH_SZ)\n",
    "    \n",
    "    gen_model.train()\n",
    "    disc_model.train()            \n",
    "\n",
    "    disc_optimizer.zero_grad()\n",
    "\n",
    "    x = x.to(device=device, dtype=dtype)\n",
    "    \n",
    "    next_frames, _ = gen_model(x, h0)\n",
    "    \n",
    "    orig_x = x[:, 1:, :]\n",
    "    recon_x = next_frames[:, :-1, :]\n",
    "    \n",
    "    logits_real = disc_model(orig_x.contiguous().view(-1, C, H, W)).squeeze()\n",
    "    logits_fake = disc_model(recon_x.contiguous().view(-1, C, H, W)).squeeze()\n",
    "    \n",
    "    all_ones = torch.ones(logits_real.shape[0], device=device)\n",
    "    all_zeros = torch.zeros(logits_real.shape[0], device=device)\n",
    "    \n",
    "    disc_err_real = criterion(logits_real, all_ones)\n",
    "    disc_err_fake = disc_err_fake_reg * criterion(logits_fake, all_zeros)    \n",
    "    \n",
    "    disc_loss = disc_err_real + disc_err_fake    \n",
    "    \n",
    "    disc_loss.backward()\n",
    "    disc_optimizer.step()    \n",
    "    \n",
    "    \n",
    "    # generator loss\n",
    "    gen_optimizer.zero_grad()    \n",
    "    \n",
    "    next_frames, _ = gen_model(x, h0)\n",
    "    recon_x = next_frames[:, :-1, :]\n",
    "    \n",
    "    gen_logits_fake = disc_model(recon_x.contiguous().view(-1, C, H, W)).squeeze()\n",
    "    gen_loss_gan = gan_reg * criterion(gen_logits_fake, all_ones)    \n",
    "    \n",
    "    MSE = F.mse_loss(orig_x, recon_x, size_average=True)\n",
    "    \n",
    "    gen_loss = MSE + gen_loss_gan\n",
    "    \n",
    "    gen_loss.backward()\n",
    "    gen_optimizer.step()\n",
    "    \n",
    "    gen_loss_str = f'recr: {MSE:.6f}, gan: {gen_loss_gan:.6f}'\n",
    "    disc_loss_str = f'real: {disc_err_real:.6f}, fake: {disc_err_fake:.6f}'    \n",
    "    \n",
    "    return gen_loss, disc_loss, gen_loss_str, disc_loss_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num parameters: 3586035\n"
     ]
    }
   ],
   "source": [
    "NUM_CHANNELS = 1\n",
    "INPUT_SIZE = IMAGE_SZ[0] * IMAGE_SZ[1] * NUM_CHANNELS   \n",
    "HIDDEN_SIZE = INPUT_SIZE\n",
    "OUTPUT_SIZE = INPUT_SIZE\n",
    "\n",
    "\n",
    "LATENT_SIZE = 95\n",
    "\n",
    "gen = LatentLSTM(latent_size=LATENT_SIZE, hidden_size=200, device=device, num_channels=NUM_CHANNELS, num_rnn_layers=1)\n",
    "disc = VAEGAN_Disc(latent_size=LATENT_SIZE, device=device, num_channels=NUM_CHANNELS)\n",
    "\n",
    "Initializer.initialize(model=gen, initialization=init.xavier_uniform_, gain=init.calculate_gain('relu'))\n",
    "Initializer.initialize(model=disc, initialization=init.xavier_uniform_, gain=init.calculate_gain('relu'))\n",
    "\n",
    "\n",
    "BEST_VAEGAN_PATH = '/home/deepdeepfakes/cs231n-project/src/backups/vaegan-mmnist/vaegan-best'\n",
    "state = torch.load(BEST_VAEGAN_PATH)\n",
    "\n",
    "# gen.vae.load_state_dict(state['gen_state_dict'])\n",
    "# disc.load_state_dict(state['disc_state_dict'])\n",
    "\n",
    "\n",
    "\n",
    "param_count = np.sum([np.prod(p.size()) for p in gen.parameters()])\n",
    "print(f'Num parameters: {param_count}')\n",
    "\n",
    "\n",
    "\n",
    "# ModelTrainer.load_model(checkpoint_path=BEST_VAEGAN_PATH, model=model.vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_DEBUG_ROOT = os.path.join(os.getcwd(), 'src', 'experiments', 'latent-lstm-xavier-no-init-long-train')\n",
    "\n",
    "gen_optimizer = optim.Adam(gen.parameters(), lr=1e-3)\n",
    "disc_optimizer = optim.Adam(disc.parameters(), lr=1e-3)\n",
    "\n",
    "trainer = ModelTrainer(gen, disc, gen_optimizer, disc_optimizer, train_fn, LSTM_DEBUG_ROOT, tags=[\"lstm\", \"lstm-gan\", \"lstm-gan-xavier-no-init\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0] (0/2500), \t gen_loss  = 0.4599 \t(recr: 0.459597, gan: 0.000281), \n",
      "\t\t\t disc_loss = 1.6948 \t(real: 0.891269, fake: 0.803512)\n",
      "\n",
      "Epoch [0] (50/2500), \t gen_loss  = 0.0378 \t(recr: 0.037394, gan: 0.000391), \n",
      "\t\t\t disc_loss = 0.7337 \t(real: 0.382829, fake: 0.350847)\n",
      "\n",
      "Epoch [0] (100/2500), \t gen_loss  = 0.0356 \t(recr: 0.034948, gan: 0.000643), \n",
      "\t\t\t disc_loss = 0.3024 \t(real: 0.153062, fake: 0.149337)\n",
      "\n",
      "Epoch [0] (150/2500), \t gen_loss  = 0.0329 \t(recr: 0.032128, gan: 0.000819), \n",
      "\t\t\t disc_loss = 0.1461 \t(real: 0.068129, fake: 0.077982)\n",
      "\n",
      "Epoch [0] (200/2500), \t gen_loss  = 0.0300 \t(recr: 0.029429, gan: 0.000568), \n",
      "\t\t\t disc_loss = 0.8331 \t(real: 0.039709, fake: 0.793357)\n",
      "\n",
      "Epoch [0] (250/2500), \t gen_loss  = 0.0322 \t(recr: 0.031252, gan: 0.000908), \n",
      "\t\t\t disc_loss = 0.1585 \t(real: 0.077263, fake: 0.081267)\n",
      "\n",
      "Epoch [0] (300/2500), \t gen_loss  = 0.0308 \t(recr: 0.029672, gan: 0.001101), \n",
      "\t\t\t disc_loss = 0.0889 \t(real: 0.055131, fake: 0.033805)\n",
      "\n",
      "Epoch [0] (350/2500), \t gen_loss  = 0.0275 \t(recr: 0.026209, gan: 0.001274), \n",
      "\t\t\t disc_loss = 0.0403 \t(real: 0.023187, fake: 0.017130)\n",
      "\n",
      "Epoch [0] (400/2500), \t gen_loss  = 0.0283 \t(recr: 0.026900, gan: 0.001382), \n",
      "\t\t\t disc_loss = 0.0276 \t(real: 0.015360, fake: 0.012202)\n",
      "\n",
      "Epoch [0] (450/2500), \t gen_loss  = 0.0261 \t(recr: 0.024844, gan: 0.001299), \n",
      "\t\t\t disc_loss = 0.0361 \t(real: 0.016995, fake: 0.019093)\n",
      "\n",
      "Epoch [0] (500/2500), \t gen_loss  = 0.0269 \t(recr: 0.025386, gan: 0.001539), \n",
      "\t\t\t disc_loss = 0.0289 \t(real: 0.021781, fake: 0.007099)\n",
      "\n",
      "Epoch [0] (550/2500), \t gen_loss  = 0.0268 \t(recr: 0.025220, gan: 0.001620), \n",
      "\t\t\t disc_loss = 0.0125 \t(real: 0.006969, fake: 0.005552)\n",
      "\n",
      "Epoch [0] (600/2500), \t gen_loss  = 0.0278 \t(recr: 0.026181, gan: 0.001635), \n",
      "\t\t\t disc_loss = 0.0118 \t(real: 0.006612, fake: 0.005201)\n",
      "\n",
      "Epoch [0] (650/2500), \t gen_loss  = 0.0277 \t(recr: 0.026094, gan: 0.001618), \n",
      "\t\t\t disc_loss = 0.0146 \t(real: 0.006900, fake: 0.007726)\n",
      "\n",
      "Epoch [0] (700/2500), \t gen_loss  = 0.0300 \t(recr: 0.028303, gan: 0.001720), \n",
      "\t\t\t disc_loss = 0.0090 \t(real: 0.004908, fake: 0.004070)\n",
      "\n",
      "Epoch [0] (750/2500), \t gen_loss  = 0.0281 \t(recr: 0.026403, gan: 0.001704), \n",
      "\t\t\t disc_loss = 0.0103 \t(real: 0.005787, fake: 0.004520)\n",
      "\n",
      "Epoch [0] (800/2500), \t gen_loss  = 0.0296 \t(recr: 0.027842, gan: 0.001770), \n",
      "\t\t\t disc_loss = 0.0089 \t(real: 0.005154, fake: 0.003766)\n",
      "\n",
      "Epoch [0] (850/2500), \t gen_loss  = 0.0288 \t(recr: 0.026928, gan: 0.001913), \n",
      "\t\t\t disc_loss = 0.0053 \t(real: 0.003139, fake: 0.002137)\n",
      "\n",
      "Epoch [0] (900/2500), \t gen_loss  = 0.0280 \t(recr: 0.026130, gan: 0.001852), \n",
      "\t\t\t disc_loss = 0.0073 \t(real: 0.004574, fake: 0.002680)\n",
      "\n",
      "Epoch [0] (950/2500), \t gen_loss  = 0.0261 \t(recr: 0.024076, gan: 0.002009), \n",
      "\t\t\t disc_loss = 0.0054 \t(real: 0.003479, fake: 0.001961)\n",
      "\n",
      "Epoch [0] (1000/2500), \t gen_loss  = 0.0267 \t(recr: 0.024799, gan: 0.001858), \n",
      "\t\t\t disc_loss = 0.0059 \t(real: 0.002905, fake: 0.002952)\n",
      "\n",
      "Epoch [0] (1050/2500), \t gen_loss  = 0.0291 \t(recr: 0.027064, gan: 0.002045), \n",
      "\t\t\t disc_loss = 0.0040 \t(real: 0.002578, fake: 0.001395)\n",
      "\n",
      "Epoch [0] (1100/2500), \t gen_loss  = 0.0272 \t(recr: 0.025287, gan: 0.001894), \n",
      "\t\t\t disc_loss = 0.0109 \t(real: 0.007856, fake: 0.003060)\n",
      "\n",
      "Epoch [0] (1150/2500), \t gen_loss  = 0.0275 \t(recr: 0.025458, gan: 0.002058), \n",
      "\t\t\t disc_loss = 0.0033 \t(real: 0.001901, fake: 0.001359)\n",
      "\n",
      "Epoch [0] (1200/2500), \t gen_loss  = 0.0276 \t(recr: 0.025698, gan: 0.001931), \n",
      "\t\t\t disc_loss = 0.0045 \t(real: 0.002210, fake: 0.002288)\n",
      "\n",
      "Epoch [0] (1250/2500), \t gen_loss  = 0.0258 \t(recr: 0.023889, gan: 0.001935), \n",
      "\t\t\t disc_loss = 0.0049 \t(real: 0.002146, fake: 0.002775)\n",
      "\n",
      "Epoch [0] (1300/2500), \t gen_loss  = 0.0269 \t(recr: 0.024835, gan: 0.002099), \n",
      "\t\t\t disc_loss = 0.0042 \t(real: 0.002632, fake: 0.001532)\n",
      "\n",
      "Epoch [0] (1350/2500), \t gen_loss  = 0.0253 \t(recr: 0.023412, gan: 0.001912), \n",
      "\t\t\t disc_loss = 0.0068 \t(real: 0.003648, fake: 0.003139)\n",
      "\n",
      "Epoch [0] (1400/2500), \t gen_loss  = 0.0270 \t(recr: 0.024964, gan: 0.001994), \n",
      "\t\t\t disc_loss = 0.0029 \t(real: 0.001278, fake: 0.001649)\n",
      "\n",
      "Epoch [0] (1450/2500), \t gen_loss  = 0.0249 \t(recr: 0.022822, gan: 0.002115), \n",
      "\t\t\t disc_loss = 0.0022 \t(real: 0.001083, fake: 0.001123)\n",
      "\n",
      "Epoch [0] (1500/2500), \t gen_loss  = 0.0271 \t(recr: 0.024952, gan: 0.002158), \n",
      "\t\t\t disc_loss = 0.0022 \t(real: 0.001182, fake: 0.001008)\n",
      "\n",
      "Epoch [0] (1550/2500), \t gen_loss  = 0.0268 \t(recr: 0.024534, gan: 0.002288), \n",
      "\t\t\t disc_loss = 0.0021 \t(real: 0.001374, fake: 0.000693)\n",
      "\n",
      "Epoch [0] (1600/2500), \t gen_loss  = 0.0261 \t(recr: 0.023947, gan: 0.002193), \n",
      "\t\t\t disc_loss = 0.0020 \t(real: 0.001184, fake: 0.000775)\n",
      "\n",
      "Epoch [0] (1650/2500), \t gen_loss  = 0.0252 \t(recr: 0.022864, gan: 0.002311), \n",
      "\t\t\t disc_loss = 0.0017 \t(real: 0.001013, fake: 0.000655)\n",
      "\n",
      "Epoch [0] (1700/2500), \t gen_loss  = 0.0249 \t(recr: 0.022640, gan: 0.002235), \n",
      "\t\t\t disc_loss = 0.0018 \t(real: 0.000950, fake: 0.000892)\n",
      "\n",
      "Epoch [0] (1750/2500), \t gen_loss  = 0.0269 \t(recr: 0.024651, gan: 0.002233), \n",
      "\t\t\t disc_loss = 0.0018 \t(real: 0.000967, fake: 0.000826)\n",
      "\n",
      "Epoch [0] (1800/2500), \t gen_loss  = 0.0252 \t(recr: 0.022884, gan: 0.002346), \n",
      "\t\t\t disc_loss = 0.0011 \t(real: 0.000635, fake: 0.000512)\n",
      "\n",
      "Epoch [0] (1850/2500), \t gen_loss  = 0.0247 \t(recr: 0.022359, gan: 0.002346), \n",
      "\t\t\t disc_loss = 0.0011 \t(real: 0.000635, fake: 0.000486)\n",
      "\n",
      "Epoch [0] (1900/2500), \t gen_loss  = 0.0261 \t(recr: 0.023669, gan: 0.002391), \n",
      "\t\t\t disc_loss = 0.0014 \t(real: 0.000876, fake: 0.000482)\n",
      "\n",
      "Epoch [0] (1950/2500), \t gen_loss  = 0.0261 \t(recr: 0.023740, gan: 0.002375), \n",
      "\t\t\t disc_loss = 0.0013 \t(real: 0.000768, fake: 0.000576)\n",
      "\n",
      "Epoch [0] (2000/2500), \t gen_loss  = 0.0258 \t(recr: 0.023425, gan: 0.002379), \n",
      "\t\t\t disc_loss = 0.0011 \t(real: 0.000570, fake: 0.000498)\n",
      "\n",
      "Epoch [0] (2050/2500), \t gen_loss  = 0.0263 \t(recr: 0.023940, gan: 0.002355), \n",
      "\t\t\t disc_loss = 0.0010 \t(real: 0.000523, fake: 0.000474)\n",
      "\n",
      "Epoch [0] (2100/2500), \t gen_loss  = 0.0258 \t(recr: 0.023426, gan: 0.002385), \n",
      "\t\t\t disc_loss = 0.0012 \t(real: 0.000660, fake: 0.000510)\n",
      "\n",
      "Epoch [0] (2150/2500), \t gen_loss  = 0.0251 \t(recr: 0.022998, gan: 0.002076), \n",
      "\t\t\t disc_loss = 0.0023 \t(real: 0.000740, fake: 0.001527)\n",
      "\n",
      "Epoch [0] (2200/2500), \t gen_loss  = 0.0265 \t(recr: 0.023965, gan: 0.002491), \n",
      "\t\t\t disc_loss = 0.0016 \t(real: 0.001157, fake: 0.000466)\n",
      "\n",
      "Epoch [0] (2250/2500), \t gen_loss  = 0.0254 \t(recr: 0.022823, gan: 0.002556), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000518, fake: 0.000280)\n",
      "\n",
      "Epoch [0] (2300/2500), \t gen_loss  = 0.0241 \t(recr: 0.021568, gan: 0.002502), \n",
      "\t\t\t disc_loss = 0.0007 \t(real: 0.000362, fake: 0.000305)\n",
      "\n",
      "Epoch [0] (2350/2500), \t gen_loss  = 0.0248 \t(recr: 0.022328, gan: 0.002472), \n",
      "\t\t\t disc_loss = 0.0078 \t(real: 0.007397, fake: 0.000356)\n",
      "\n",
      "Epoch [0] (2400/2500), \t gen_loss  = 0.0257 \t(recr: 0.023293, gan: 0.002437), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000443, fake: 0.000453)\n",
      "\n",
      "Epoch [0] (2450/2500), \t gen_loss  = 0.0258 \t(recr: 0.023406, gan: 0.002368), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000329, fake: 0.000482)\n",
      "\n",
      "Epoch [0] done                                 \n",
      "Epoch [1] (0/2500), \t gen_loss  = 0.0248 \t(recr: 0.022265, gan: 0.002570), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000316, fake: 0.000260)\n",
      "\n",
      "Epoch [1] (50/2500), \t gen_loss  = 0.0254 \t(recr: 0.022847, gan: 0.002584), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000519, fake: 0.000324)\n",
      "\n",
      "Epoch [1] (100/2500), \t gen_loss  = 0.0250 \t(recr: 0.022443, gan: 0.002547), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000537, fake: 0.000321)\n",
      "\n",
      "Epoch [1] (150/2500), \t gen_loss  = 0.0246 \t(recr: 0.022011, gan: 0.002603), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000256, fake: 0.000239)\n",
      "\n",
      "Epoch [1] (200/2500), \t gen_loss  = 0.0238 \t(recr: 0.021245, gan: 0.002580), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000272, fake: 0.000307)\n",
      "\n",
      "Epoch [1] (250/2500), \t gen_loss  = 0.0249 \t(recr: 0.022145, gan: 0.002728), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000264, fake: 0.000167)\n",
      "\n",
      "Epoch [1] (300/2500), \t gen_loss  = 0.0238 \t(recr: 0.021080, gan: 0.002688), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000332, fake: 0.000203)\n",
      "\n",
      "Epoch [1] (350/2500), \t gen_loss  = 0.0254 \t(recr: 0.022860, gan: 0.002577), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000273, fake: 0.000271)\n",
      "\n",
      "Epoch [1] (400/2500), \t gen_loss  = 0.0254 \t(recr: 0.022705, gan: 0.002700), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000319, fake: 0.000162)\n",
      "\n",
      "Epoch [1] (450/2500), \t gen_loss  = 0.0259 \t(recr: 0.023254, gan: 0.002635), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000298, fake: 0.000220)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] (500/2500), \t gen_loss  = 0.0235 \t(recr: 0.020930, gan: 0.002619), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000199, fake: 0.000280)\n",
      "\n",
      "Epoch [1] (550/2500), \t gen_loss  = 0.0248 \t(recr: 0.022183, gan: 0.002632), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000168, fake: 0.000231)\n",
      "\n",
      "Epoch [1] (600/2500), \t gen_loss  = 0.0251 \t(recr: 0.022447, gan: 0.002629), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000179, fake: 0.000290)\n",
      "\n",
      "Epoch [1] (650/2500), \t gen_loss  = 0.0233 \t(recr: 0.021180, gan: 0.002143), \n",
      "\t\t\t disc_loss = 0.0045 \t(real: 0.001014, fake: 0.003534)\n",
      "\n",
      "Epoch [1] (700/2500), \t gen_loss  = 0.0250 \t(recr: 0.023298, gan: 0.001720), \n",
      "\t\t\t disc_loss = 0.0121 \t(real: 0.006241, fake: 0.005895)\n",
      "\n",
      "Epoch [1] (750/2500), \t gen_loss  = 0.0218 \t(recr: 0.019947, gan: 0.001866), \n",
      "\t\t\t disc_loss = 0.0051 \t(real: 0.002221, fake: 0.002844)\n",
      "\n",
      "Epoch [1] (800/2500), \t gen_loss  = 0.0233 \t(recr: 0.021258, gan: 0.002003), \n",
      "\t\t\t disc_loss = 0.0037 \t(real: 0.001952, fake: 0.001741)\n",
      "\n",
      "Epoch [1] (850/2500), \t gen_loss  = 0.0229 \t(recr: 0.020853, gan: 0.002027), \n",
      "\t\t\t disc_loss = 0.0031 \t(real: 0.001339, fake: 0.001743)\n",
      "\n",
      "Epoch [1] (900/2500), \t gen_loss  = 0.0217 \t(recr: 0.019649, gan: 0.002073), \n",
      "\t\t\t disc_loss = 0.0042 \t(real: 0.002327, fake: 0.001869)\n",
      "\n",
      "Epoch [1] (950/2500), \t gen_loss  = 0.0228 \t(recr: 0.020687, gan: 0.002152), \n",
      "\t\t\t disc_loss = 0.0030 \t(real: 0.001685, fake: 0.001321)\n",
      "\n",
      "Epoch [1] (1000/2500), \t gen_loss  = 0.0221 \t(recr: 0.020020, gan: 0.002093), \n",
      "\t\t\t disc_loss = 0.0028 \t(real: 0.001387, fake: 0.001459)\n",
      "\n",
      "Epoch [1] (1050/2500), \t gen_loss  = 0.0229 \t(recr: 0.021026, gan: 0.001884), \n",
      "\t\t\t disc_loss = 0.0048 \t(real: 0.001653, fake: 0.003134)\n",
      "\n",
      "Epoch [1] (1100/2500), \t gen_loss  = 0.0228 \t(recr: 0.020895, gan: 0.001950), \n",
      "\t\t\t disc_loss = 0.0038 \t(real: 0.001548, fake: 0.002253)\n",
      "\n",
      "Epoch [1] (1150/2500), \t gen_loss  = 0.0253 \t(recr: 0.023418, gan: 0.001843), \n",
      "\t\t\t disc_loss = 0.0044 \t(real: 0.001518, fake: 0.002918)\n",
      "\n",
      "Epoch [1] (1200/2500), \t gen_loss  = 0.0229 \t(recr: 0.020809, gan: 0.002092), \n",
      "\t\t\t disc_loss = 0.0046 \t(real: 0.002948, fake: 0.001621)\n",
      "\n",
      "Epoch [1] (1250/2500), \t gen_loss  = 0.0223 \t(recr: 0.019930, gan: 0.002334), \n",
      "\t\t\t disc_loss = 0.0019 \t(real: 0.001311, fake: 0.000549)\n",
      "\n",
      "Epoch [1] (1300/2500), \t gen_loss  = 0.0222 \t(recr: 0.019954, gan: 0.002286), \n",
      "\t\t\t disc_loss = 0.0017 \t(real: 0.000836, fake: 0.000840)\n",
      "\n",
      "Epoch [1] (1350/2500), \t gen_loss  = 0.0221 \t(recr: 0.019729, gan: 0.002325), \n",
      "\t\t\t disc_loss = 0.0013 \t(real: 0.000756, fake: 0.000548)\n",
      "\n",
      "Epoch [1] (1400/2500), \t gen_loss  = 0.0221 \t(recr: 0.019840, gan: 0.002290), \n",
      "\t\t\t disc_loss = 0.0014 \t(real: 0.000792, fake: 0.000632)\n",
      "\n",
      "Epoch [1] (1450/2500), \t gen_loss  = 0.0228 \t(recr: 0.020322, gan: 0.002499), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000608, fake: 0.000293)\n",
      "\n",
      "Epoch [1] (1500/2500), \t gen_loss  = 0.0224 \t(recr: 0.019935, gan: 0.002437), \n",
      "\t\t\t disc_loss = 0.0011 \t(real: 0.000699, fake: 0.000427)\n",
      "\n",
      "Epoch [1] (1550/2500), \t gen_loss  = 0.0213 \t(recr: 0.018948, gan: 0.002348), \n",
      "\t\t\t disc_loss = 0.0012 \t(real: 0.000624, fake: 0.000533)\n",
      "\n",
      "Epoch [1] (1600/2500), \t gen_loss  = 0.0218 \t(recr: 0.019566, gan: 0.002208), \n",
      "\t\t\t disc_loss = 0.0017 \t(real: 0.000499, fake: 0.001184)\n",
      "\n",
      "Epoch [1] (1650/2500), \t gen_loss  = 0.0223 \t(recr: 0.019866, gan: 0.002452), \n",
      "\t\t\t disc_loss = 0.0011 \t(real: 0.000616, fake: 0.000518)\n",
      "\n",
      "Epoch [1] (1700/2500), \t gen_loss  = 0.0209 \t(recr: 0.018821, gan: 0.002123), \n",
      "\t\t\t disc_loss = 0.0027 \t(real: 0.001251, fake: 0.001490)\n",
      "\n",
      "Epoch [1] (1750/2500), \t gen_loss  = 0.0223 \t(recr: 0.019714, gan: 0.002592), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000465, fake: 0.000327)\n",
      "\n",
      "Epoch [1] (1800/2500), \t gen_loss  = 0.0236 \t(recr: 0.021323, gan: 0.002316), \n",
      "\t\t\t disc_loss = 0.0015 \t(real: 0.000839, fake: 0.000642)\n",
      "\n",
      "Epoch [1] (1850/2500), \t gen_loss  = 0.0205 \t(recr: 0.018063, gan: 0.002473), \n",
      "\t\t\t disc_loss = 0.0010 \t(real: 0.000553, fake: 0.000444)\n",
      "\n",
      "Epoch [1] (1900/2500), \t gen_loss  = 0.0228 \t(recr: 0.020165, gan: 0.002611), \n",
      "\t\t\t disc_loss = 0.0007 \t(real: 0.000429, fake: 0.000230)\n",
      "\n",
      "Epoch [1] (1950/2500), \t gen_loss  = 0.0211 \t(recr: 0.018634, gan: 0.002437), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000403, fake: 0.000467)\n",
      "\n",
      "Epoch [1] (2000/2500), \t gen_loss  = 0.0220 \t(recr: 0.019277, gan: 0.002711), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000300, fake: 0.000187)\n",
      "\n",
      "Epoch [1] (2050/2500), \t gen_loss  = 0.0218 \t(recr: 0.019063, gan: 0.002760), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000466, fake: 0.000145)\n",
      "\n",
      "Epoch [1] (2100/2500), \t gen_loss  = 0.0221 \t(recr: 0.019279, gan: 0.002853), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000359, fake: 0.000121)\n",
      "\n",
      "Epoch [1] (2150/2500), \t gen_loss  = 0.0214 \t(recr: 0.018736, gan: 0.002639), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000344, fake: 0.000232)\n",
      "\n",
      "Epoch [1] (2200/2500), \t gen_loss  = 0.0215 \t(recr: 0.018802, gan: 0.002701), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000380, fake: 0.000194)\n",
      "\n",
      "Epoch [1] (2250/2500), \t gen_loss  = 0.0219 \t(recr: 0.019127, gan: 0.002739), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000411, fake: 0.000175)\n",
      "\n",
      "Epoch [1] (2300/2500), \t gen_loss  = 0.0214 \t(recr: 0.018632, gan: 0.002752), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000302, fake: 0.000227)\n",
      "\n",
      "Epoch [1] (2350/2500), \t gen_loss  = 0.0205 \t(recr: 0.017787, gan: 0.002693), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000248, fake: 0.000167)\n",
      "\n",
      "Epoch [1] (2400/2500), \t gen_loss  = 0.0202 \t(recr: 0.017526, gan: 0.002689), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000245, fake: 0.000187)\n",
      "\n",
      "Epoch [1] (2450/2500), \t gen_loss  = 0.0211 \t(recr: 0.018337, gan: 0.002774), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000297, fake: 0.000140)\n",
      "\n",
      "Epoch [1] done                                 \n",
      "Epoch [2] (0/2500), \t gen_loss  = 0.0211 \t(recr: 0.018699, gan: 0.002422), \n",
      "\t\t\t disc_loss = 0.0015 \t(real: 0.000789, fake: 0.000756)\n",
      "\n",
      "Epoch [2] (50/2500), \t gen_loss  = 0.0227 \t(recr: 0.020254, gan: 0.002417), \n",
      "\t\t\t disc_loss = 0.0024 \t(real: 0.001713, fake: 0.000680)\n",
      "\n",
      "Epoch [2] (100/2500), \t gen_loss  = 0.0220 \t(recr: 0.019075, gan: 0.002883), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000758, fake: 0.000104)\n",
      "\n",
      "Epoch [2] (150/2500), \t gen_loss  = 0.0210 \t(recr: 0.018179, gan: 0.002826), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000258, fake: 0.000169)\n",
      "\n",
      "Epoch [2] (200/2500), \t gen_loss  = 0.0205 \t(recr: 0.017675, gan: 0.002864), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000195, fake: 0.000134)\n",
      "\n",
      "Epoch [2] (250/2500), \t gen_loss  = 0.0203 \t(recr: 0.017427, gan: 0.002902), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000809, fake: 0.000100)\n",
      "\n",
      "Epoch [2] (300/2500), \t gen_loss  = 0.0179 \t(recr: 0.017540, gan: 0.000333), \n",
      "\t\t\t disc_loss = 0.9771 \t(real: 0.468663, fake: 0.508467)\n",
      "\n",
      "Epoch [2] (350/2500), \t gen_loss  = 0.0199 \t(recr: 0.019084, gan: 0.000779), \n",
      "\t\t\t disc_loss = 0.2112 \t(real: 0.101784, fake: 0.109408)\n",
      "\n",
      "Epoch [2] (400/2500), \t gen_loss  = 0.0197 \t(recr: 0.018534, gan: 0.001179), \n",
      "\t\t\t disc_loss = 0.0611 \t(real: 0.030542, fake: 0.030601)\n",
      "\n",
      "Epoch [2] (450/2500), \t gen_loss  = 0.0203 \t(recr: 0.018970, gan: 0.001367), \n",
      "\t\t\t disc_loss = 0.0529 \t(real: 0.041416, fake: 0.011531)\n",
      "\n",
      "Epoch [2] (500/2500), \t gen_loss  = 0.0190 \t(recr: 0.017531, gan: 0.001420), \n",
      "\t\t\t disc_loss = 0.0143 \t(real: 0.002345, fake: 0.011978)\n",
      "\n",
      "Epoch [2] (550/2500), \t gen_loss  = 0.0204 \t(recr: 0.019063, gan: 0.001304), \n",
      "\t\t\t disc_loss = 0.0842 \t(real: 0.067734, fake: 0.016492)\n",
      "\n",
      "Epoch [2] (600/2500), \t gen_loss  = 0.0202 \t(recr: 0.018618, gan: 0.001585), \n",
      "\t\t\t disc_loss = 0.0145 \t(real: 0.007438, fake: 0.007052)\n",
      "\n",
      "Epoch [2] (650/2500), \t gen_loss  = 0.0200 \t(recr: 0.018380, gan: 0.001657), \n",
      "\t\t\t disc_loss = 0.0064 \t(real: 0.000993, fake: 0.005451)\n",
      "\n",
      "Epoch [2] (700/2500), \t gen_loss  = 0.0207 \t(recr: 0.018930, gan: 0.001782), \n",
      "\t\t\t disc_loss = 0.0054 \t(real: 0.001951, fake: 0.003449)\n",
      "\n",
      "Epoch [2] (750/2500), \t gen_loss  = 0.0210 \t(recr: 0.019181, gan: 0.001813), \n",
      "\t\t\t disc_loss = 0.0062 \t(real: 0.003174, fake: 0.003015)\n",
      "\n",
      "Epoch [2] (800/2500), \t gen_loss  = 0.0218 \t(recr: 0.019907, gan: 0.001867), \n",
      "\t\t\t disc_loss = 0.0032 \t(real: 0.000693, fake: 0.002542)\n",
      "\n",
      "Epoch [2] (850/2500), \t gen_loss  = 0.0200 \t(recr: 0.018106, gan: 0.001908), \n",
      "\t\t\t disc_loss = 0.0110 \t(real: 0.008597, fake: 0.002364)\n",
      "\n",
      "Epoch [2] (900/2500), \t gen_loss  = 0.0198 \t(recr: 0.018105, gan: 0.001743), \n",
      "\t\t\t disc_loss = 0.0072 \t(real: 0.001898, fake: 0.005265)\n",
      "\n",
      "Epoch [2] (950/2500), \t gen_loss  = 0.0203 \t(recr: 0.018452, gan: 0.001823), \n",
      "\t\t\t disc_loss = 0.0058 \t(real: 0.002341, fake: 0.003432)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2] (1000/2500), \t gen_loss  = 0.0200 \t(recr: 0.018020, gan: 0.001991), \n",
      "\t\t\t disc_loss = 0.0033 \t(real: 0.001359, fake: 0.001976)\n",
      "\n",
      "Epoch [2] (1050/2500), \t gen_loss  = 0.0200 \t(recr: 0.018024, gan: 0.001961), \n",
      "\t\t\t disc_loss = 0.0027 \t(real: 0.000829, fake: 0.001899)\n",
      "\n",
      "Epoch [2] (1100/2500), \t gen_loss  = 0.0189 \t(recr: 0.016853, gan: 0.002051), \n",
      "\t\t\t disc_loss = 0.0023 \t(real: 0.000844, fake: 0.001449)\n",
      "\n",
      "Epoch [2] (1150/2500), \t gen_loss  = 0.0189 \t(recr: 0.016822, gan: 0.002047), \n",
      "\t\t\t disc_loss = 0.0031 \t(real: 0.001651, fake: 0.001442)\n",
      "\n",
      "Epoch [2] (1200/2500), \t gen_loss  = 0.0191 \t(recr: 0.017118, gan: 0.002021), \n",
      "\t\t\t disc_loss = 0.0026 \t(real: 0.000602, fake: 0.001963)\n",
      "\n",
      "Epoch [2] (1250/2500), \t gen_loss  = 0.0202 \t(recr: 0.018142, gan: 0.002043), \n",
      "\t\t\t disc_loss = 0.0022 \t(real: 0.000634, fake: 0.001532)\n",
      "\n",
      "Epoch [2] (1300/2500), \t gen_loss  = 0.0194 \t(recr: 0.017348, gan: 0.002052), \n",
      "\t\t\t disc_loss = 0.0021 \t(real: 0.000565, fake: 0.001550)\n",
      "\n",
      "Epoch [2] (1350/2500), \t gen_loss  = 0.0189 \t(recr: 0.016781, gan: 0.002138), \n",
      "\t\t\t disc_loss = 0.0015 \t(real: 0.000438, fake: 0.001057)\n",
      "\n",
      "Epoch [2] (1400/2500), \t gen_loss  = 0.0195 \t(recr: 0.017297, gan: 0.002161), \n",
      "\t\t\t disc_loss = 0.0021 \t(real: 0.001083, fake: 0.001053)\n",
      "\n",
      "Epoch [2] (1450/2500), \t gen_loss  = 0.0193 \t(recr: 0.017166, gan: 0.002164), \n",
      "\t\t\t disc_loss = 0.0016 \t(real: 0.000572, fake: 0.001029)\n",
      "\n",
      "Epoch [2] (1500/2500), \t gen_loss  = 0.0194 \t(recr: 0.017172, gan: 0.002194), \n",
      "\t\t\t disc_loss = 0.0016 \t(real: 0.000682, fake: 0.000908)\n",
      "\n",
      "Epoch [2] (1550/2500), \t gen_loss  = 0.0201 \t(recr: 0.017936, gan: 0.002208), \n",
      "\t\t\t disc_loss = 0.0022 \t(real: 0.001179, fake: 0.000973)\n",
      "\n",
      "Epoch [2] (1600/2500), \t gen_loss  = 0.0192 \t(recr: 0.017011, gan: 0.002197), \n",
      "\t\t\t disc_loss = 0.0013 \t(real: 0.000422, fake: 0.000865)\n",
      "\n",
      "Epoch [2] (1650/2500), \t gen_loss  = 0.0210 \t(recr: 0.018778, gan: 0.002189), \n",
      "\t\t\t disc_loss = 0.0031 \t(real: 0.002170, fake: 0.000978)\n",
      "\n",
      "Epoch [2] (1700/2500), \t gen_loss  = 0.0188 \t(recr: 0.016533, gan: 0.002262), \n",
      "\t\t\t disc_loss = 0.0016 \t(real: 0.000803, fake: 0.000824)\n",
      "\n",
      "Epoch [2] (1750/2500), \t gen_loss  = 0.0195 \t(recr: 0.017324, gan: 0.002209), \n",
      "\t\t\t disc_loss = 0.0014 \t(real: 0.000484, fake: 0.000873)\n",
      "\n",
      "Epoch [2] (1800/2500), \t gen_loss  = 0.0198 \t(recr: 0.017499, gan: 0.002309), \n",
      "\t\t\t disc_loss = 0.0015 \t(real: 0.000777, fake: 0.000692)\n",
      "\n",
      "Epoch [2] (1850/2500), \t gen_loss  = 0.0200 \t(recr: 0.017760, gan: 0.002277), \n",
      "\t\t\t disc_loss = 0.0011 \t(real: 0.000378, fake: 0.000721)\n",
      "\n",
      "Epoch [2] (1900/2500), \t gen_loss  = 0.0199 \t(recr: 0.017629, gan: 0.002320), \n",
      "\t\t\t disc_loss = 0.0012 \t(real: 0.000567, fake: 0.000585)\n",
      "\n",
      "Epoch [2] (1950/2500), \t gen_loss  = 0.0187 \t(recr: 0.016341, gan: 0.002312), \n",
      "\t\t\t disc_loss = 0.0011 \t(real: 0.000281, fake: 0.000776)\n",
      "\n",
      "Epoch [2] (2000/2500), \t gen_loss  = 0.0190 \t(recr: 0.016654, gan: 0.002318), \n",
      "\t\t\t disc_loss = 0.0011 \t(real: 0.000469, fake: 0.000620)\n",
      "\n",
      "Epoch [2] (2050/2500), \t gen_loss  = 0.0204 \t(recr: 0.018027, gan: 0.002358), \n",
      "\t\t\t disc_loss = 0.0013 \t(real: 0.000775, fake: 0.000544)\n",
      "\n",
      "Epoch [2] (2100/2500), \t gen_loss  = 0.0187 \t(recr: 0.016455, gan: 0.002235), \n",
      "\t\t\t disc_loss = 0.0016 \t(real: 0.000755, fake: 0.000829)\n",
      "\n",
      "Epoch [2] (2150/2500), \t gen_loss  = 0.0186 \t(recr: 0.016307, gan: 0.002338), \n",
      "\t\t\t disc_loss = 0.0011 \t(real: 0.000592, fake: 0.000537)\n",
      "\n",
      "Epoch [2] (2200/2500), \t gen_loss  = 0.0185 \t(recr: 0.016146, gan: 0.002360), \n",
      "\t\t\t disc_loss = 0.0011 \t(real: 0.000525, fake: 0.000570)\n",
      "\n",
      "Epoch [2] (2250/2500), \t gen_loss  = 0.0200 \t(recr: 0.017590, gan: 0.002402), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000476, fake: 0.000463)\n",
      "\n",
      "Epoch [2] (2300/2500), \t gen_loss  = 0.0202 \t(recr: 0.017775, gan: 0.002423), \n",
      "\t\t\t disc_loss = 0.0010 \t(real: 0.000464, fake: 0.000577)\n",
      "\n",
      "Epoch [2] (2350/2500), \t gen_loss  = 0.0182 \t(recr: 0.015845, gan: 0.002343), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000282, fake: 0.000569)\n",
      "\n",
      "Epoch [2] (2400/2500), \t gen_loss  = 0.0190 \t(recr: 0.016589, gan: 0.002407), \n",
      "\t\t\t disc_loss = 0.0021 \t(real: 0.001670, fake: 0.000431)\n",
      "\n",
      "Epoch [2] (2450/2500), \t gen_loss  = 0.0190 \t(recr: 0.016471, gan: 0.002480), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000270, fake: 0.000362)\n",
      "\n",
      "Epoch [2] done                                 \n",
      "Epoch [3] (0/2500), \t gen_loss  = 0.0198 \t(recr: 0.017595, gan: 0.002174), \n",
      "\t\t\t disc_loss = 0.0019 \t(real: 0.001019, fake: 0.000843)\n",
      "\n",
      "Epoch [3] (50/2500), \t gen_loss  = 0.0180 \t(recr: 0.015789, gan: 0.002176), \n",
      "\t\t\t disc_loss = 0.0042 \t(real: 0.002712, fake: 0.001465)\n",
      "\n",
      "Epoch [3] (100/2500), \t gen_loss  = 0.0192 \t(recr: 0.016922, gan: 0.002322), \n",
      "\t\t\t disc_loss = 0.0011 \t(real: 0.000425, fake: 0.000638)\n",
      "\n",
      "Epoch [3] (150/2500), \t gen_loss  = 0.0185 \t(recr: 0.016085, gan: 0.002402), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000317, fake: 0.000481)\n",
      "\n",
      "Epoch [3] (200/2500), \t gen_loss  = 0.0185 \t(recr: 0.016144, gan: 0.002378), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000257, fake: 0.000542)\n",
      "\n",
      "Epoch [3] (250/2500), \t gen_loss  = 0.0194 \t(recr: 0.017098, gan: 0.002294), \n",
      "\t\t\t disc_loss = 0.0010 \t(real: 0.000324, fake: 0.000660)\n",
      "\n",
      "Epoch [3] (300/2500), \t gen_loss  = 0.0190 \t(recr: 0.016711, gan: 0.002320), \n",
      "\t\t\t disc_loss = 0.0010 \t(real: 0.000220, fake: 0.000773)\n",
      "\n",
      "Epoch [3] (350/2500), \t gen_loss  = 0.0177 \t(recr: 0.015328, gan: 0.002386), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000356, fake: 0.000563)\n",
      "\n",
      "Epoch [3] (400/2500), \t gen_loss  = 0.0181 \t(recr: 0.015575, gan: 0.002526), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000157, fake: 0.000312)\n",
      "\n",
      "Epoch [3] (450/2500), \t gen_loss  = 0.0191 \t(recr: 0.016522, gan: 0.002557), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000175, fake: 0.000305)\n",
      "\n",
      "Epoch [3] (500/2500), \t gen_loss  = 0.0175 \t(recr: 0.014912, gan: 0.002552), \n",
      "\t\t\t disc_loss = 0.0014 \t(real: 0.001114, fake: 0.000265)\n",
      "\n",
      "Epoch [3] (550/2500), \t gen_loss  = 0.0188 \t(recr: 0.016312, gan: 0.002511), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000271, fake: 0.000312)\n",
      "\n",
      "Epoch [3] (600/2500), \t gen_loss  = 0.0182 \t(recr: 0.015830, gan: 0.002346), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000376, fake: 0.000534)\n",
      "\n",
      "Epoch [3] (650/2500), \t gen_loss  = 0.0179 \t(recr: 0.015381, gan: 0.002501), \n",
      "\t\t\t disc_loss = 0.0007 \t(real: 0.000407, fake: 0.000303)\n",
      "\n",
      "Epoch [3] (700/2500), \t gen_loss  = 0.0190 \t(recr: 0.016444, gan: 0.002522), \n",
      "\t\t\t disc_loss = 0.0007 \t(real: 0.000319, fake: 0.000346)\n",
      "\n",
      "Epoch [3] (750/2500), \t gen_loss  = 0.0193 \t(recr: 0.016749, gan: 0.002592), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000287, fake: 0.000289)\n",
      "\n",
      "Epoch [3] (800/2500), \t gen_loss  = 0.0193 \t(recr: 0.016710, gan: 0.002593), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000152, fake: 0.000258)\n",
      "\n",
      "Epoch [3] (850/2500), \t gen_loss  = 0.0190 \t(recr: 0.016390, gan: 0.002646), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000135, fake: 0.000206)\n",
      "\n",
      "Epoch [3] (900/2500), \t gen_loss  = 0.0184 \t(recr: 0.015867, gan: 0.002566), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000156, fake: 0.000326)\n",
      "\n",
      "Epoch [3] (950/2500), \t gen_loss  = 0.0186 \t(recr: 0.015936, gan: 0.002653), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000379, fake: 0.000186)\n",
      "\n",
      "Epoch [3] (1000/2500), \t gen_loss  = 0.0180 \t(recr: 0.015321, gan: 0.002694), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000157, fake: 0.000173)\n",
      "\n",
      "Epoch [3] (1050/2500), \t gen_loss  = 0.0182 \t(recr: 0.015518, gan: 0.002661), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000145, fake: 0.000219)\n",
      "\n",
      "Epoch [3] (1100/2500), \t gen_loss  = 0.0177 \t(recr: 0.014969, gan: 0.002734), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000131, fake: 0.000163)\n",
      "\n",
      "Epoch [3] (1150/2500), \t gen_loss  = 0.0189 \t(recr: 0.016242, gan: 0.002691), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000265, fake: 0.000248)\n",
      "\n",
      "Epoch [3] (1200/2500), \t gen_loss  = 0.0181 \t(recr: 0.015321, gan: 0.002762), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000112, fake: 0.000143)\n",
      "\n",
      "Epoch [3] (1250/2500), \t gen_loss  = 0.0173 \t(recr: 0.014605, gan: 0.002737), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000107, fake: 0.000166)\n",
      "\n",
      "Epoch [3] (1300/2500), \t gen_loss  = 0.0187 \t(recr: 0.015867, gan: 0.002790), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000115, fake: 0.000135)\n",
      "\n",
      "Epoch [3] (1350/2500), \t gen_loss  = 0.0181 \t(recr: 0.015408, gan: 0.002688), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000200, fake: 0.000219)\n",
      "\n",
      "Epoch [3] (1400/2500), \t gen_loss  = 0.0195 \t(recr: 0.016714, gan: 0.002791), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000259, fake: 0.000133)\n",
      "\n",
      "Epoch [3] (1450/2500), \t gen_loss  = 0.0185 \t(recr: 0.015746, gan: 0.002736), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000212, fake: 0.000172)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3] (1500/2500), \t gen_loss  = 0.0181 \t(recr: 0.015388, gan: 0.002724), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000113, fake: 0.000169)\n",
      "\n",
      "Epoch [3] (1550/2500), \t gen_loss  = 0.0185 \t(recr: 0.015739, gan: 0.002773), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000091, fake: 0.000132)\n",
      "\n",
      "Epoch [3] (1600/2500), \t gen_loss  = 0.0194 \t(recr: 0.016451, gan: 0.002907), \n",
      "\t\t\t disc_loss = 0.0049 \t(real: 0.004667, fake: 0.000242)\n",
      "\n",
      "Epoch [3] (1650/2500), \t gen_loss  = 0.0182 \t(recr: 0.015389, gan: 0.002817), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000172, fake: 0.000209)\n",
      "\n",
      "Epoch [3] (1700/2500), \t gen_loss  = 0.0190 \t(recr: 0.016149, gan: 0.002864), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000283, fake: 0.000140)\n",
      "\n",
      "Epoch [3] (1750/2500), \t gen_loss  = 0.0191 \t(recr: 0.016191, gan: 0.002879), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000119, fake: 0.000119)\n",
      "\n",
      "Epoch [3] (1800/2500), \t gen_loss  = 0.0181 \t(recr: 0.015269, gan: 0.002794), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000127, fake: 0.000137)\n",
      "\n",
      "Epoch [3] (1850/2500), \t gen_loss  = 0.0175 \t(recr: 0.014641, gan: 0.002838), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000110, fake: 0.000117)\n",
      "\n",
      "Epoch [3] (1900/2500), \t gen_loss  = 0.0191 \t(recr: 0.016265, gan: 0.002824), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000316, fake: 0.000154)\n",
      "\n",
      "Epoch [3] (1950/2500), \t gen_loss  = 0.0177 \t(recr: 0.014864, gan: 0.002839), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000204, fake: 0.000120)\n",
      "\n",
      "Epoch [3] (2000/2500), \t gen_loss  = 0.0186 \t(recr: 0.015786, gan: 0.002804), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000090, fake: 0.000136)\n",
      "\n",
      "Epoch [3] (2050/2500), \t gen_loss  = 0.0181 \t(recr: 0.015218, gan: 0.002872), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000097, fake: 0.000093)\n",
      "\n",
      "Epoch [3] (2100/2500), \t gen_loss  = 0.0191 \t(recr: 0.016060, gan: 0.002998), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000104, fake: 0.000063)\n",
      "\n",
      "Epoch [3] (2150/2500), \t gen_loss  = 0.0192 \t(recr: 0.016226, gan: 0.002963), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000149, fake: 0.000089)\n",
      "\n",
      "Epoch [3] (2200/2500), \t gen_loss  = 0.0198 \t(recr: 0.016874, gan: 0.002891), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000090, fake: 0.000112)\n",
      "\n",
      "Epoch [3] (2250/2500), \t gen_loss  = 0.0175 \t(recr: 0.014600, gan: 0.002908), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000124, fake: 0.000130)\n",
      "\n",
      "Epoch [3] (2300/2500), \t gen_loss  = 0.0183 \t(recr: 0.015228, gan: 0.003074), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000289, fake: 0.000071)\n",
      "\n",
      "Epoch [3] (2350/2500), \t gen_loss  = 0.0192 \t(recr: 0.016718, gan: 0.002438), \n",
      "\t\t\t disc_loss = 0.0014 \t(real: 0.000358, fake: 0.001043)\n",
      "\n",
      "Epoch [3] (2400/2500), \t gen_loss  = 0.0186 \t(recr: 0.015773, gan: 0.002825), \n",
      "\t\t\t disc_loss = 0.0014 \t(real: 0.001001, fake: 0.000447)\n",
      "\n",
      "Epoch [3] (2450/2500), \t gen_loss  = 0.0178 \t(recr: 0.014995, gan: 0.002758), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000162, fake: 0.000180)\n",
      "\n",
      "Epoch [3] done                                 \n",
      "Epoch [4] (0/2500), \t gen_loss  = 0.0183 \t(recr: 0.015489, gan: 0.002787), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000122, fake: 0.000128)\n",
      "\n",
      "Epoch [4] (50/2500), \t gen_loss  = 0.0184 \t(recr: 0.015579, gan: 0.002865), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000099, fake: 0.000108)\n",
      "\n",
      "Epoch [4] (100/2500), \t gen_loss  = 0.0188 \t(recr: 0.015879, gan: 0.002884), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000141, fake: 0.000105)\n",
      "\n",
      "Epoch [4] (150/2500), \t gen_loss  = 0.0175 \t(recr: 0.014637, gan: 0.002842), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000089, fake: 0.000108)\n",
      "\n",
      "Epoch [4] (200/2500), \t gen_loss  = 0.0192 \t(recr: 0.016357, gan: 0.002845), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000125, fake: 0.000117)\n",
      "\n",
      "Epoch [4] (250/2500), \t gen_loss  = 0.0180 \t(recr: 0.015046, gan: 0.002937), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000098, fake: 0.000093)\n",
      "\n",
      "Epoch [4] (300/2500), \t gen_loss  = 0.0183 \t(recr: 0.015472, gan: 0.002852), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000119, fake: 0.000100)\n",
      "\n",
      "Epoch [4] (350/2500), \t gen_loss  = 0.0183 \t(recr: 0.015314, gan: 0.002985), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000098, fake: 0.000086)\n",
      "\n",
      "Epoch [4] (400/2500), \t gen_loss  = 0.0172 \t(recr: 0.014285, gan: 0.002957), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000130, fake: 0.000072)\n",
      "\n",
      "Epoch [4] (450/2500), \t gen_loss  = 0.0188 \t(recr: 0.015790, gan: 0.002979), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000077, fake: 0.000089)\n",
      "\n",
      "Epoch [4] (500/2500), \t gen_loss  = 0.0188 \t(recr: 0.015803, gan: 0.003006), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000090, fake: 0.000063)\n",
      "\n",
      "Epoch [4] (550/2500), \t gen_loss  = 0.0180 \t(recr: 0.014988, gan: 0.002984), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000123, fake: 0.000079)\n",
      "\n",
      "Epoch [4] (600/2500), \t gen_loss  = 0.0188 \t(recr: 0.015841, gan: 0.002965), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000097, fake: 0.000100)\n",
      "\n",
      "Epoch [4] (650/2500), \t gen_loss  = 0.0178 \t(recr: 0.014809, gan: 0.003033), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000090, fake: 0.000065)\n",
      "\n",
      "Epoch [4] (700/2500), \t gen_loss  = 0.0185 \t(recr: 0.015500, gan: 0.003033), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000060, fake: 0.000056)\n",
      "\n",
      "Epoch [4] (750/2500), \t gen_loss  = 0.0184 \t(recr: 0.015296, gan: 0.003108), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000104, fake: 0.000061)\n",
      "\n",
      "Epoch [4] (800/2500), \t gen_loss  = 0.0186 \t(recr: 0.015457, gan: 0.003123), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000060, fake: 0.000044)\n",
      "\n",
      "Epoch [4] (850/2500), \t gen_loss  = 0.0187 \t(recr: 0.015743, gan: 0.002994), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000058, fake: 0.000086)\n",
      "\n",
      "Epoch [4] (900/2500), \t gen_loss  = 0.0188 \t(recr: 0.015642, gan: 0.003135), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000059, fake: 0.000040)\n",
      "\n",
      "Epoch [4] (950/2500), \t gen_loss  = 0.0183 \t(recr: 0.015318, gan: 0.002980), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000064, fake: 0.000089)\n",
      "\n",
      "Epoch [4] (1000/2500), \t gen_loss  = 0.0182 \t(recr: 0.015045, gan: 0.003134), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000103, fake: 0.000046)\n",
      "\n",
      "Epoch [4] (1050/2500), \t gen_loss  = 0.0184 \t(recr: 0.015258, gan: 0.003106), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000090, fake: 0.000053)\n",
      "\n",
      "Epoch [4] (1100/2500), \t gen_loss  = 0.0183 \t(recr: 0.015526, gan: 0.002812), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000069, fake: 0.000153)\n",
      "\n",
      "Epoch [4] (1150/2500), \t gen_loss  = 0.0173 \t(recr: 0.014130, gan: 0.003206), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000062, fake: 0.000041)\n",
      "\n",
      "Epoch [4] (1200/2500), \t gen_loss  = 0.0187 \t(recr: 0.015764, gan: 0.002923), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000078, fake: 0.000106)\n",
      "\n",
      "Epoch [4] (1250/2500), \t gen_loss  = 0.0184 \t(recr: 0.015123, gan: 0.003288), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000043, fake: 0.000030)\n",
      "\n",
      "Epoch [4] (1300/2500), \t gen_loss  = 0.0187 \t(recr: 0.015472, gan: 0.003251), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000082, fake: 0.000041)\n",
      "\n",
      "Epoch [4] (1350/2500), \t gen_loss  = 0.0188 \t(recr: 0.015544, gan: 0.003246), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000048, fake: 0.000032)\n",
      "\n",
      "Epoch [4] (1400/2500), \t gen_loss  = 0.0178 \t(recr: 0.014597, gan: 0.003204), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000076, fake: 0.000044)\n",
      "\n",
      "Epoch [4] (1450/2500), \t gen_loss  = 0.0184 \t(recr: 0.015198, gan: 0.003235), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000062, fake: 0.000036)\n",
      "\n",
      "Epoch [4] (1500/2500), \t gen_loss  = 0.0190 \t(recr: 0.015718, gan: 0.003235), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000076, fake: 0.000030)\n",
      "\n",
      "Epoch [4] (1550/2500), \t gen_loss  = 0.0188 \t(recr: 0.015578, gan: 0.003226), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000050, fake: 0.000044)\n",
      "\n",
      "Epoch [4] (1600/2500), \t gen_loss  = 0.0182 \t(recr: 0.014912, gan: 0.003244), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000056, fake: 0.000030)\n",
      "\n",
      "Epoch [4] (1650/2500), \t gen_loss  = 0.0178 \t(recr: 0.014395, gan: 0.003360), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000047, fake: 0.000020)\n",
      "\n",
      "Epoch [4] (1700/2500), \t gen_loss  = 0.0188 \t(recr: 0.015438, gan: 0.003324), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000050, fake: 0.000025)\n",
      "\n",
      "Epoch [4] (1750/2500), \t gen_loss  = 0.0188 \t(recr: 0.015528, gan: 0.003267), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000041, fake: 0.000030)\n",
      "\n",
      "Epoch [4] (1800/2500), \t gen_loss  = 0.0183 \t(recr: 0.015050, gan: 0.003266), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000041, fake: 0.000036)\n",
      "\n",
      "Epoch [4] (1850/2500), \t gen_loss  = 0.0193 \t(recr: 0.016064, gan: 0.003283), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000077, fake: 0.000028)\n",
      "\n",
      "Epoch [4] (1900/2500), \t gen_loss  = 0.0180 \t(recr: 0.014640, gan: 0.003324), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000059, fake: 0.000044)\n",
      "\n",
      "Epoch [4] (1950/2500), \t gen_loss  = 0.0181 \t(recr: 0.015230, gan: 0.002913), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000133, fake: 0.000131)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4] (2000/2500), \t gen_loss  = 0.0187 \t(recr: 0.015717, gan: 0.002934), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000039, fake: 0.000095)\n",
      "\n",
      "Epoch [4] (2050/2500), \t gen_loss  = 0.0182 \t(recr: 0.014761, gan: 0.003417), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000114, fake: 0.000020)\n",
      "\n",
      "Epoch [4] (2100/2500), \t gen_loss  = 0.0178 \t(recr: 0.014474, gan: 0.003363), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000036, fake: 0.000028)\n",
      "\n",
      "Epoch [4] (2150/2500), \t gen_loss  = 0.0181 \t(recr: 0.014862, gan: 0.003277), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000065, fake: 0.000026)\n",
      "\n",
      "Epoch [4] (2200/2500), \t gen_loss  = 0.0176 \t(recr: 0.014205, gan: 0.003411), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000045, fake: 0.000023)\n",
      "\n",
      "Epoch [4] (2250/2500), \t gen_loss  = 0.0186 \t(recr: 0.015224, gan: 0.003370), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000041, fake: 0.000019)\n",
      "\n",
      "Epoch [4] (2300/2500), \t gen_loss  = 0.0185 \t(recr: 0.015092, gan: 0.003445), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000060, fake: 0.000019)\n",
      "\n",
      "Epoch [4] (2350/2500), \t gen_loss  = 0.0182 \t(recr: 0.014828, gan: 0.003347), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000182, fake: 0.000033)\n",
      "\n",
      "Epoch [4] (2400/2500), \t gen_loss  = 0.0182 \t(recr: 0.014854, gan: 0.003314), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000049, fake: 0.000027)\n",
      "\n",
      "Epoch [4] (2450/2500), \t gen_loss  = 0.0183 \t(recr: 0.015149, gan: 0.003189), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000039, fake: 0.000068)\n",
      "\n",
      "Epoch [4] done                                 \n",
      "Epoch [5] (0/2500), \t gen_loss  = 0.0185 \t(recr: 0.015073, gan: 0.003432), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000043, fake: 0.000023)\n",
      "\n",
      "Epoch [5] (50/2500), \t gen_loss  = 0.0192 \t(recr: 0.016098, gan: 0.003127), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000082, fake: 0.000069)\n",
      "\n",
      "Epoch [5] (100/2500), \t gen_loss  = 0.0173 \t(recr: 0.015839, gan: 0.001464), \n",
      "\t\t\t disc_loss = 0.2270 \t(real: 0.079569, fake: 0.147389)\n",
      "\n",
      "Epoch [5] (150/2500), \t gen_loss  = 0.0169 \t(recr: 0.014973, gan: 0.001973), \n",
      "\t\t\t disc_loss = 0.0369 \t(real: 0.012994, fake: 0.023936)\n",
      "\n",
      "Epoch [5] (200/2500), \t gen_loss  = 0.0173 \t(recr: 0.016061, gan: 0.001271), \n",
      "\t\t\t disc_loss = 0.0549 \t(real: 0.007551, fake: 0.047346)\n",
      "\n",
      "Epoch [5] (250/2500), \t gen_loss  = 0.0173 \t(recr: 0.014988, gan: 0.002296), \n",
      "\t\t\t disc_loss = 0.0110 \t(real: 0.004379, fake: 0.006651)\n",
      "\n",
      "Epoch [5] (300/2500), \t gen_loss  = 0.0177 \t(recr: 0.015708, gan: 0.002033), \n",
      "\t\t\t disc_loss = 0.0098 \t(real: 0.004850, fake: 0.004937)\n",
      "\n",
      "Epoch [5] (350/2500), \t gen_loss  = 0.0173 \t(recr: 0.015344, gan: 0.002003), \n",
      "\t\t\t disc_loss = 0.0751 \t(real: 0.065717, fake: 0.009350)\n",
      "\n",
      "Epoch [5] (400/2500), \t gen_loss  = 0.0176 \t(recr: 0.015311, gan: 0.002275), \n",
      "\t\t\t disc_loss = 0.0368 \t(real: 0.027985, fake: 0.008800)\n",
      "\n",
      "Epoch [5] (450/2500), \t gen_loss  = 0.0168 \t(recr: 0.015243, gan: 0.001598), \n",
      "\t\t\t disc_loss = 0.0344 \t(real: 0.006174, fake: 0.028196)\n",
      "\n",
      "Epoch [5] (500/2500), \t gen_loss  = 0.0157 \t(recr: 0.013985, gan: 0.001705), \n",
      "\t\t\t disc_loss = 0.0153 \t(real: 0.005157, fake: 0.010164)\n",
      "\n",
      "Epoch [5] (550/2500), \t gen_loss  = 0.0155 \t(recr: 0.013776, gan: 0.001685), \n",
      "\t\t\t disc_loss = 0.0118 \t(real: 0.003778, fake: 0.008009)\n",
      "\n",
      "Epoch [5] (600/2500), \t gen_loss  = 0.0165 \t(recr: 0.014250, gan: 0.002220), \n",
      "\t\t\t disc_loss = 0.0096 \t(real: 0.007180, fake: 0.002413)\n",
      "\n",
      "Epoch [5] (650/2500), \t gen_loss  = 0.0169 \t(recr: 0.014997, gan: 0.001889), \n",
      "\t\t\t disc_loss = 0.0082 \t(real: 0.002102, fake: 0.006084)\n",
      "\n",
      "Epoch [5] (700/2500), \t gen_loss  = 0.0167 \t(recr: 0.015120, gan: 0.001531), \n",
      "\t\t\t disc_loss = 0.0401 \t(real: 0.003994, fake: 0.036127)\n",
      "\n",
      "Epoch [5] (750/2500), \t gen_loss  = 0.0195 \t(recr: 0.016382, gan: 0.003155), \n",
      "\t\t\t disc_loss = 0.0038 \t(real: 0.003447, fake: 0.000308)\n",
      "\n",
      "Epoch [5] (800/2500), \t gen_loss  = 0.0183 \t(recr: 0.015467, gan: 0.002803), \n",
      "\t\t\t disc_loss = 0.0051 \t(real: 0.004218, fake: 0.000882)\n",
      "\n",
      "Epoch [5] (850/2500), \t gen_loss  = 0.0183 \t(recr: 0.016142, gan: 0.002136), \n",
      "\t\t\t disc_loss = 0.0103 \t(real: 0.004784, fake: 0.005488)\n",
      "\n",
      "Epoch [5] (900/2500), \t gen_loss  = 0.0178 \t(recr: 0.015448, gan: 0.002342), \n",
      "\t\t\t disc_loss = 0.0089 \t(real: 0.002436, fake: 0.006435)\n",
      "\n",
      "Epoch [5] (950/2500), \t gen_loss  = 0.0173 \t(recr: 0.015115, gan: 0.002161), \n",
      "\t\t\t disc_loss = 0.0039 \t(real: 0.000853, fake: 0.003014)\n",
      "\n",
      "Epoch [5] (1000/2500), \t gen_loss  = 0.0168 \t(recr: 0.014818, gan: 0.001986), \n",
      "\t\t\t disc_loss = 0.0062 \t(real: 0.000841, fake: 0.005359)\n",
      "\n",
      "Epoch [5] (1050/2500), \t gen_loss  = 0.0169 \t(recr: 0.014614, gan: 0.002304), \n",
      "\t\t\t disc_loss = 0.0022 \t(real: 0.001252, fake: 0.000914)\n",
      "\n",
      "Epoch [5] (1100/2500), \t gen_loss  = 0.0164 \t(recr: 0.014021, gan: 0.002330), \n",
      "\t\t\t disc_loss = 0.0029 \t(real: 0.001178, fake: 0.001718)\n",
      "\n",
      "Epoch [5] (1150/2500), \t gen_loss  = 0.0176 \t(recr: 0.015233, gan: 0.002342), \n",
      "\t\t\t disc_loss = 0.0032 \t(real: 0.001523, fake: 0.001642)\n",
      "\n",
      "Epoch [5] (1200/2500), \t gen_loss  = 0.0183 \t(recr: 0.015880, gan: 0.002429), \n",
      "\t\t\t disc_loss = 0.0026 \t(real: 0.000983, fake: 0.001586)\n",
      "\n",
      "Epoch [5] (1250/2500), \t gen_loss  = 0.0172 \t(recr: 0.014935, gan: 0.002296), \n",
      "\t\t\t disc_loss = 0.0031 \t(real: 0.000854, fake: 0.002218)\n",
      "\n",
      "Epoch [5] (1300/2500), \t gen_loss  = 0.0180 \t(recr: 0.016130, gan: 0.001917), \n",
      "\t\t\t disc_loss = 0.2980 \t(real: 0.290211, fake: 0.007759)\n",
      "\n",
      "Epoch [5] (1350/2500), \t gen_loss  = 0.0194 \t(recr: 0.016482, gan: 0.002948), \n",
      "\t\t\t disc_loss = 0.0048 \t(real: 0.002691, fake: 0.002070)\n",
      "\n",
      "Epoch [5] (1400/2500), \t gen_loss  = 0.0169 \t(recr: 0.014803, gan: 0.002066), \n",
      "\t\t\t disc_loss = 0.0092 \t(real: 0.005077, fake: 0.004128)\n",
      "\n",
      "Epoch [5] (1450/2500), \t gen_loss  = 0.0169 \t(recr: 0.014768, gan: 0.002171), \n",
      "\t\t\t disc_loss = 0.0054 \t(real: 0.001971, fake: 0.003442)\n",
      "\n",
      "Epoch [5] (1500/2500), \t gen_loss  = 0.0163 \t(recr: 0.014319, gan: 0.002027), \n",
      "\t\t\t disc_loss = 0.0074 \t(real: 0.001262, fake: 0.006105)\n",
      "\n",
      "Epoch [5] (1550/2500), \t gen_loss  = 0.0169 \t(recr: 0.014599, gan: 0.002304), \n",
      "\t\t\t disc_loss = 0.0027 \t(real: 0.000865, fake: 0.001883)\n",
      "\n",
      "Epoch [5] (1600/2500), \t gen_loss  = 0.0159 \t(recr: 0.013623, gan: 0.002307), \n",
      "\t\t\t disc_loss = 0.0031 \t(real: 0.000620, fake: 0.002489)\n",
      "\n",
      "Epoch [5] (1650/2500), \t gen_loss  = 0.0176 \t(recr: 0.015039, gan: 0.002542), \n",
      "\t\t\t disc_loss = 0.0019 \t(real: 0.000791, fake: 0.001100)\n",
      "\n",
      "Epoch [5] (1700/2500), \t gen_loss  = 0.0170 \t(recr: 0.014725, gan: 0.002308), \n",
      "\t\t\t disc_loss = 0.0021 \t(real: 0.000387, fake: 0.001712)\n",
      "\n",
      "Epoch [5] (1750/2500), \t gen_loss  = 0.0172 \t(recr: 0.015139, gan: 0.002083), \n",
      "\t\t\t disc_loss = 0.0049 \t(real: 0.000684, fake: 0.004195)\n",
      "\n",
      "Epoch [5] (1800/2500), \t gen_loss  = 0.0177 \t(recr: 0.015247, gan: 0.002423), \n",
      "\t\t\t disc_loss = 0.0025 \t(real: 0.000915, fake: 0.001602)\n",
      "\n",
      "Epoch [5] (1850/2500), \t gen_loss  = 0.0180 \t(recr: 0.014973, gan: 0.003076), \n",
      "\t\t\t disc_loss = 0.0019 \t(real: 0.000936, fake: 0.001008)\n",
      "\n",
      "Epoch [5] (1900/2500), \t gen_loss  = 0.0179 \t(recr: 0.015126, gan: 0.002768), \n",
      "\t\t\t disc_loss = 0.0019 \t(real: 0.000820, fake: 0.001108)\n",
      "\n",
      "Epoch [5] (1950/2500), \t gen_loss  = 0.0175 \t(recr: 0.014745, gan: 0.002764), \n",
      "\t\t\t disc_loss = 0.0012 \t(real: 0.000500, fake: 0.000657)\n",
      "\n",
      "Epoch [5] (2000/2500), \t gen_loss  = 0.0167 \t(recr: 0.013986, gan: 0.002749), \n",
      "\t\t\t disc_loss = 0.0010 \t(real: 0.000353, fake: 0.000633)\n",
      "\n",
      "Epoch [5] (2050/2500), \t gen_loss  = 0.0174 \t(recr: 0.014669, gan: 0.002745), \n",
      "\t\t\t disc_loss = 0.0011 \t(real: 0.000445, fake: 0.000695)\n",
      "\n",
      "Epoch [5] (2100/2500), \t gen_loss  = 0.0165 \t(recr: 0.013887, gan: 0.002647), \n",
      "\t\t\t disc_loss = 0.0010 \t(real: 0.000309, fake: 0.000678)\n",
      "\n",
      "Epoch [5] (2150/2500), \t gen_loss  = 0.0179 \t(recr: 0.015215, gan: 0.002706), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000270, fake: 0.000536)\n",
      "\n",
      "Epoch [5] (2200/2500), \t gen_loss  = 0.0166 \t(recr: 0.013936, gan: 0.002670), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000443, fake: 0.000426)\n",
      "\n",
      "Epoch [5] (2250/2500), \t gen_loss  = 0.0176 \t(recr: 0.014982, gan: 0.002596), \n",
      "\t\t\t disc_loss = 0.0019 \t(real: 0.001242, fake: 0.000657)\n",
      "\n",
      "Epoch [5] (2300/2500), \t gen_loss  = 0.0171 \t(recr: 0.014425, gan: 0.002651), \n",
      "\t\t\t disc_loss = 0.0007 \t(real: 0.000260, fake: 0.000464)\n",
      "\n",
      "Epoch [5] (2350/2500), \t gen_loss  = 0.0180 \t(recr: 0.015260, gan: 0.002697), \n",
      "\t\t\t disc_loss = 0.0007 \t(real: 0.000331, fake: 0.000370)\n",
      "\n",
      "Epoch [5] (2400/2500), \t gen_loss  = 0.0161 \t(recr: 0.013510, gan: 0.002631), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000341, fake: 0.000463)\n",
      "\n",
      "Epoch [5] (2450/2500), \t gen_loss  = 0.0164 \t(recr: 0.013780, gan: 0.002627), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000441, fake: 0.000508)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5] done                                 \n",
      "Epoch [6] (0/2500), \t gen_loss  = 0.0172 \t(recr: 0.014558, gan: 0.002634), \n",
      "\t\t\t disc_loss = 0.0007 \t(real: 0.000189, fake: 0.000476)\n",
      "\n",
      "Epoch [6] (50/2500), \t gen_loss  = 0.0171 \t(recr: 0.014354, gan: 0.002763), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000195, fake: 0.000430)\n",
      "\n",
      "Epoch [6] (100/2500), \t gen_loss  = 0.0165 \t(recr: 0.013754, gan: 0.002760), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000156, fake: 0.000614)\n",
      "\n",
      "Epoch [6] (150/2500), \t gen_loss  = 0.0171 \t(recr: 0.014417, gan: 0.002733), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000245, fake: 0.000550)\n",
      "\n",
      "Epoch [6] (200/2500), \t gen_loss  = 0.0173 \t(recr: 0.014599, gan: 0.002708), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000214, fake: 0.000559)\n",
      "\n",
      "Epoch [6] (250/2500), \t gen_loss  = 0.0158 \t(recr: 0.012977, gan: 0.002845), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000280, fake: 0.000511)\n",
      "\n",
      "Epoch [6] (300/2500), \t gen_loss  = 0.0172 \t(recr: 0.014391, gan: 0.002850), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000241, fake: 0.000288)\n",
      "\n",
      "Epoch [6] (350/2500), \t gen_loss  = 0.0177 \t(recr: 0.014801, gan: 0.002880), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000232, fake: 0.000298)\n",
      "\n",
      "Epoch [6] (400/2500), \t gen_loss  = 0.0171 \t(recr: 0.014274, gan: 0.002825), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000187, fake: 0.000318)\n",
      "\n",
      "Epoch [6] (450/2500), \t gen_loss  = 0.0172 \t(recr: 0.014440, gan: 0.002796), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000120, fake: 0.000331)\n",
      "\n",
      "Epoch [6] (500/2500), \t gen_loss  = 0.0167 \t(recr: 0.013874, gan: 0.002839), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000342, fake: 0.000279)\n",
      "\n",
      "Epoch [6] (550/2500), \t gen_loss  = 0.0159 \t(recr: 0.013085, gan: 0.002766), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000400, fake: 0.000536)\n",
      "\n",
      "Epoch [6] (600/2500), \t gen_loss  = 0.0179 \t(recr: 0.015101, gan: 0.002764), \n",
      "\t\t\t disc_loss = 0.0007 \t(real: 0.000251, fake: 0.000479)\n",
      "\n",
      "Epoch [6] (650/2500), \t gen_loss  = 0.0180 \t(recr: 0.015300, gan: 0.002671), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000267, fake: 0.000592)\n",
      "\n",
      "Epoch [6] (700/2500), \t gen_loss  = 0.0181 \t(recr: 0.015266, gan: 0.002846), \n",
      "\t\t\t disc_loss = 0.0007 \t(real: 0.000389, fake: 0.000361)\n",
      "\n",
      "Epoch [6] (750/2500), \t gen_loss  = 0.0183 \t(recr: 0.015691, gan: 0.002659), \n",
      "\t\t\t disc_loss = 0.0007 \t(real: 0.000126, fake: 0.000543)\n",
      "\n",
      "Epoch [6] (800/2500), \t gen_loss  = 0.0162 \t(recr: 0.013546, gan: 0.002677), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000287, fake: 0.000601)\n",
      "\n",
      "Epoch [6] (850/2500), \t gen_loss  = 0.0166 \t(recr: 0.013895, gan: 0.002742), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000156, fake: 0.000465)\n",
      "\n",
      "Epoch [6] (900/2500), \t gen_loss  = 0.0176 \t(recr: 0.014790, gan: 0.002820), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000365, fake: 0.000410)\n",
      "\n",
      "Epoch [6] (950/2500), \t gen_loss  = 0.0168 \t(recr: 0.013974, gan: 0.002805), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000272, fake: 0.000307)\n",
      "\n",
      "Epoch [6] (1000/2500), \t gen_loss  = 0.0166 \t(recr: 0.013662, gan: 0.002900), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000162, fake: 0.000250)\n",
      "\n",
      "Epoch [6] (1050/2500), \t gen_loss  = 0.0174 \t(recr: 0.014397, gan: 0.003031), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000255, fake: 0.000194)\n",
      "\n",
      "Epoch [6] (1100/2500), \t gen_loss  = 0.0170 \t(recr: 0.014033, gan: 0.002987), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000192, fake: 0.000228)\n",
      "\n",
      "Epoch [6] (1150/2500), \t gen_loss  = 0.0173 \t(recr: 0.014289, gan: 0.003021), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000177, fake: 0.000225)\n",
      "\n",
      "Epoch [6] (1200/2500), \t gen_loss  = 0.0166 \t(recr: 0.013493, gan: 0.003118), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000153, fake: 0.000203)\n",
      "\n",
      "Epoch [6] (1250/2500), \t gen_loss  = 0.0163 \t(recr: 0.013300, gan: 0.003031), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000143, fake: 0.000223)\n",
      "\n",
      "Epoch [6] (1300/2500), \t gen_loss  = 0.0170 \t(recr: 0.013916, gan: 0.003066), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000291, fake: 0.000138)\n",
      "\n",
      "Epoch [6] (1350/2500), \t gen_loss  = 0.0174 \t(recr: 0.014463, gan: 0.002914), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000343, fake: 0.000245)\n",
      "\n",
      "Epoch [6] (1400/2500), \t gen_loss  = 0.0179 \t(recr: 0.014808, gan: 0.003048), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000132, fake: 0.000191)\n",
      "\n",
      "Epoch [6] (1450/2500), \t gen_loss  = 0.0167 \t(recr: 0.013836, gan: 0.002890), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000174, fake: 0.000221)\n",
      "\n",
      "Epoch [6] (1500/2500), \t gen_loss  = 0.0166 \t(recr: 0.013605, gan: 0.002991), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000222, fake: 0.000140)\n",
      "\n",
      "Epoch [6] (1550/2500), \t gen_loss  = 0.0177 \t(recr: 0.014816, gan: 0.002934), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000197, fake: 0.000163)\n",
      "\n",
      "Epoch [6] (1600/2500), \t gen_loss  = 0.0167 \t(recr: 0.013603, gan: 0.003084), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000192, fake: 0.000186)\n",
      "\n",
      "Epoch [6] (1650/2500), \t gen_loss  = 0.0166 \t(recr: 0.013550, gan: 0.003004), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000328, fake: 0.000140)\n",
      "\n",
      "Epoch [6] (1700/2500), \t gen_loss  = 0.0173 \t(recr: 0.014313, gan: 0.003003), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000181, fake: 0.000157)\n",
      "\n",
      "Epoch [6] (1750/2500), \t gen_loss  = 0.0167 \t(recr: 0.013637, gan: 0.003113), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000124, fake: 0.000120)\n",
      "\n",
      "Epoch [6] (1800/2500), \t gen_loss  = 0.0177 \t(recr: 0.014615, gan: 0.003049), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000130, fake: 0.000164)\n",
      "\n",
      "Epoch [6] (1850/2500), \t gen_loss  = 0.0175 \t(recr: 0.014345, gan: 0.003147), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000133, fake: 0.000099)\n",
      "\n",
      "Epoch [6] (1900/2500), \t gen_loss  = 0.0164 \t(recr: 0.013279, gan: 0.003099), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000096, fake: 0.000083)\n",
      "\n",
      "Epoch [6] (1950/2500), \t gen_loss  = 0.0178 \t(recr: 0.014587, gan: 0.003168), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000131, fake: 0.000104)\n",
      "\n",
      "Epoch [6] (2000/2500), \t gen_loss  = 0.0171 \t(recr: 0.014020, gan: 0.003107), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000155, fake: 0.000157)\n",
      "\n",
      "Epoch [6] (2050/2500), \t gen_loss  = 0.0164 \t(recr: 0.013268, gan: 0.003097), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000153, fake: 0.000119)\n",
      "\n",
      "Epoch [6] (2100/2500), \t gen_loss  = 0.0174 \t(recr: 0.014213, gan: 0.003224), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000083, fake: 0.000089)\n",
      "\n",
      "Epoch [6] (2150/2500), \t gen_loss  = 0.0181 \t(recr: 0.014973, gan: 0.003169), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000167, fake: 0.000112)\n",
      "\n",
      "Epoch [6] (2200/2500), \t gen_loss  = 0.0178 \t(recr: 0.014658, gan: 0.003166), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000073, fake: 0.000126)\n",
      "\n",
      "Epoch [6] (2250/2500), \t gen_loss  = 0.0168 \t(recr: 0.013590, gan: 0.003181), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000146, fake: 0.000101)\n",
      "\n",
      "Epoch [6] (2300/2500), \t gen_loss  = 0.0166 \t(recr: 0.013418, gan: 0.003163), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000072, fake: 0.000100)\n",
      "\n",
      "Epoch [6] (2350/2500), \t gen_loss  = 0.0180 \t(recr: 0.014913, gan: 0.003127), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000174, fake: 0.000102)\n",
      "\n",
      "Epoch [6] (2400/2500), \t gen_loss  = 0.0181 \t(recr: 0.015018, gan: 0.003116), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000065, fake: 0.000114)\n",
      "\n",
      "Epoch [6] (2450/2500), \t gen_loss  = 0.0169 \t(recr: 0.013770, gan: 0.003135), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000095, fake: 0.000121)\n",
      "\n",
      "Epoch [6] done                                 \n",
      "Epoch [7] (0/2500), \t gen_loss  = 0.0176 \t(recr: 0.014397, gan: 0.003159), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000089, fake: 0.000097)\n",
      "\n",
      "Epoch [7] (50/2500), \t gen_loss  = 0.0171 \t(recr: 0.013945, gan: 0.003204), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000098, fake: 0.000078)\n",
      "\n",
      "Epoch [7] (100/2500), \t gen_loss  = 0.0163 \t(recr: 0.013195, gan: 0.003098), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000082, fake: 0.000135)\n",
      "\n",
      "Epoch [7] (150/2500), \t gen_loss  = 0.0168 \t(recr: 0.013580, gan: 0.003221), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000080, fake: 0.000081)\n",
      "\n",
      "Epoch [7] (200/2500), \t gen_loss  = 0.0178 \t(recr: 0.014646, gan: 0.003136), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000093, fake: 0.000150)\n",
      "\n",
      "Epoch [7] (250/2500), \t gen_loss  = 0.0175 \t(recr: 0.014294, gan: 0.003186), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000082, fake: 0.000094)\n",
      "\n",
      "Epoch [7] (300/2500), \t gen_loss  = 0.0175 \t(recr: 0.014165, gan: 0.003307), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000265, fake: 0.000057)\n",
      "\n",
      "Epoch [7] (350/2500), \t gen_loss  = 0.0165 \t(recr: 0.013324, gan: 0.003218), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000089, fake: 0.000083)\n",
      "\n",
      "Epoch [7] (400/2500), \t gen_loss  = 0.0169 \t(recr: 0.013856, gan: 0.003043), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000078, fake: 0.000259)\n",
      "\n",
      "Epoch [7] (450/2500), \t gen_loss  = 0.0176 \t(recr: 0.015252, gan: 0.002346), \n",
      "\t\t\t disc_loss = 5.7479 \t(real: 5.747869, fake: 0.000072)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7] (500/2500), \t gen_loss  = 0.0174 \t(recr: 0.015931, gan: 0.001428), \n",
      "\t\t\t disc_loss = 0.0645 \t(real: 0.010207, fake: 0.054315)\n",
      "\n",
      "Epoch [7] (550/2500), \t gen_loss  = 0.0187 \t(recr: 0.017085, gan: 0.001625), \n",
      "\t\t\t disc_loss = 0.0329 \t(real: 0.011647, fake: 0.021212)\n",
      "\n",
      "Epoch [7] (600/2500), \t gen_loss  = 0.0209 \t(recr: 0.018306, gan: 0.002565), \n",
      "\t\t\t disc_loss = 0.0128 \t(real: 0.011511, fake: 0.001326)\n",
      "\n",
      "Epoch [7] (650/2500), \t gen_loss  = 0.0172 \t(recr: 0.015735, gan: 0.001476), \n",
      "\t\t\t disc_loss = 0.0390 \t(real: 0.011334, fake: 0.027628)\n",
      "\n",
      "Epoch [7] (700/2500), \t gen_loss  = 0.0189 \t(recr: 0.016283, gan: 0.002662), \n",
      "\t\t\t disc_loss = 0.0018 \t(real: 0.000473, fake: 0.001325)\n",
      "\n",
      "Epoch [7] (750/2500), \t gen_loss  = 0.0183 \t(recr: 0.015462, gan: 0.002853), \n",
      "\t\t\t disc_loss = 0.0017 \t(real: 0.000579, fake: 0.001162)\n",
      "\n",
      "Epoch [7] (800/2500), \t gen_loss  = 0.0157 \t(recr: 0.013907, gan: 0.001832), \n",
      "\t\t\t disc_loss = 0.0115 \t(real: 0.001547, fake: 0.009981)\n",
      "\n",
      "Epoch [7] (850/2500), \t gen_loss  = 0.0171 \t(recr: 0.014920, gan: 0.002165), \n",
      "\t\t\t disc_loss = 0.0031 \t(real: 0.001038, fake: 0.002013)\n",
      "\n",
      "Epoch [7] (900/2500), \t gen_loss  = 0.0166 \t(recr: 0.014371, gan: 0.002201), \n",
      "\t\t\t disc_loss = 0.0024 \t(real: 0.000432, fake: 0.001945)\n",
      "\n",
      "Epoch [7] (950/2500), \t gen_loss  = 0.0164 \t(recr: 0.014300, gan: 0.002056), \n",
      "\t\t\t disc_loss = 0.0031 \t(real: 0.000476, fake: 0.002633)\n",
      "\n",
      "Epoch [7] (1000/2500), \t gen_loss  = 0.0176 \t(recr: 0.015192, gan: 0.002385), \n",
      "\t\t\t disc_loss = 0.0017 \t(real: 0.000690, fake: 0.001025)\n",
      "\n",
      "Epoch [7] (1050/2500), \t gen_loss  = 0.0172 \t(recr: 0.014903, gan: 0.002297), \n",
      "\t\t\t disc_loss = 0.0026 \t(real: 0.000693, fake: 0.001938)\n",
      "\n",
      "Epoch [7] (1100/2500), \t gen_loss  = 0.0165 \t(recr: 0.014213, gan: 0.002242), \n",
      "\t\t\t disc_loss = 0.0022 \t(real: 0.000577, fake: 0.001646)\n",
      "\n",
      "Epoch [7] (1150/2500), \t gen_loss  = 0.0179 \t(recr: 0.015548, gan: 0.002361), \n",
      "\t\t\t disc_loss = 0.0024 \t(real: 0.001302, fake: 0.001098)\n",
      "\n",
      "Epoch [7] (1200/2500), \t gen_loss  = 0.0182 \t(recr: 0.015532, gan: 0.002687), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000395, fake: 0.000469)\n",
      "\n",
      "Epoch [7] (1250/2500), \t gen_loss  = 0.0182 \t(recr: 0.015430, gan: 0.002752), \n",
      "\t\t\t disc_loss = 0.0007 \t(real: 0.000413, fake: 0.000304)\n",
      "\n",
      "Epoch [7] (1300/2500), \t gen_loss  = 0.0163 \t(recr: 0.013884, gan: 0.002431), \n",
      "\t\t\t disc_loss = 0.0013 \t(real: 0.000381, fake: 0.000908)\n",
      "\n",
      "Epoch [7] (1350/2500), \t gen_loss  = 0.0171 \t(recr: 0.014615, gan: 0.002460), \n",
      "\t\t\t disc_loss = 0.0012 \t(real: 0.000458, fake: 0.000710)\n",
      "\n",
      "Epoch [7] (1400/2500), \t gen_loss  = 0.0196 \t(recr: 0.016799, gan: 0.002845), \n",
      "\t\t\t disc_loss = 0.0010 \t(real: 0.000792, fake: 0.000202)\n",
      "\n",
      "Epoch [7] (1450/2500), \t gen_loss  = 0.0178 \t(recr: 0.014966, gan: 0.002854), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000554, fake: 0.000215)\n",
      "\n",
      "Epoch [7] (1500/2500), \t gen_loss  = 0.0179 \t(recr: 0.015378, gan: 0.002490), \n",
      "\t\t\t disc_loss = 0.0032 \t(real: 0.002518, fake: 0.000674)\n",
      "\n",
      "Epoch [7] (1550/2500), \t gen_loss  = 0.0185 \t(recr: 0.015851, gan: 0.002666), \n",
      "\t\t\t disc_loss = 0.0015 \t(real: 0.001155, fake: 0.000348)\n",
      "\n",
      "Epoch [7] (1600/2500), \t gen_loss  = 0.0176 \t(recr: 0.014920, gan: 0.002679), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000368, fake: 0.000437)\n",
      "\n",
      "Epoch [7] (1650/2500), \t gen_loss  = 0.0190 \t(recr: 0.016236, gan: 0.002810), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000594, fake: 0.000292)\n",
      "\n",
      "Epoch [7] (1700/2500), \t gen_loss  = 0.0173 \t(recr: 0.014905, gan: 0.002411), \n",
      "\t\t\t disc_loss = 0.0011 \t(real: 0.000136, fake: 0.000934)\n",
      "\n",
      "Epoch [7] (1750/2500), \t gen_loss  = 0.0177 \t(recr: 0.015066, gan: 0.002667), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000204, fake: 0.000305)\n",
      "\n",
      "Epoch [7] (1800/2500), \t gen_loss  = 0.0166 \t(recr: 0.014122, gan: 0.002514), \n",
      "\t\t\t disc_loss = 0.0012 \t(real: 0.000488, fake: 0.000676)\n",
      "\n",
      "Epoch [7] (1850/2500), \t gen_loss  = 0.0181 \t(recr: 0.015608, gan: 0.002448), \n",
      "\t\t\t disc_loss = 0.0009 \t(real: 0.000132, fake: 0.000810)\n",
      "\n",
      "Epoch [7] (1900/2500), \t gen_loss  = 0.0196 \t(recr: 0.016861, gan: 0.002713), \n",
      "\t\t\t disc_loss = 0.0017 \t(real: 0.001250, fake: 0.000409)\n",
      "\n",
      "Epoch [7] (1950/2500), \t gen_loss  = 0.0174 \t(recr: 0.014978, gan: 0.002411), \n",
      "\t\t\t disc_loss = 0.0017 \t(real: 0.000247, fake: 0.001464)\n",
      "\n",
      "Epoch [7] (2000/2500), \t gen_loss  = 0.0181 \t(recr: 0.015613, gan: 0.002511), \n",
      "\t\t\t disc_loss = 0.0012 \t(real: 0.000265, fake: 0.000946)\n",
      "\n",
      "Epoch [7] (2050/2500), \t gen_loss  = 0.0160 \t(recr: 0.015092, gan: 0.000862), \n",
      "\t\t\t disc_loss = 0.3137 \t(real: 0.184664, fake: 0.129016)\n",
      "\n",
      "Epoch [7] (2100/2500), \t gen_loss  = 0.0181 \t(recr: 0.015376, gan: 0.002755), \n",
      "\t\t\t disc_loss = 0.0147 \t(real: 0.012977, fake: 0.001728)\n",
      "\n",
      "Epoch [7] (2150/2500), \t gen_loss  = 0.0171 \t(recr: 0.014894, gan: 0.002223), \n",
      "\t\t\t disc_loss = 0.0090 \t(real: 0.002189, fake: 0.006854)\n",
      "\n",
      "Epoch [7] (2200/2500), \t gen_loss  = 0.0160 \t(recr: 0.013505, gan: 0.002495), \n",
      "\t\t\t disc_loss = 0.0033 \t(real: 0.000950, fake: 0.002322)\n",
      "\n",
      "Epoch [7] (2250/2500), \t gen_loss  = 0.0152 \t(recr: 0.012991, gan: 0.002227), \n",
      "\t\t\t disc_loss = 0.0090 \t(real: 0.000796, fake: 0.008249)\n",
      "\n",
      "Epoch [7] (2300/2500), \t gen_loss  = 0.0170 \t(recr: 0.014427, gan: 0.002560), \n",
      "\t\t\t disc_loss = 0.0036 \t(real: 0.001802, fake: 0.001748)\n",
      "\n",
      "Epoch [7] (2350/2500), \t gen_loss  = 0.0154 \t(recr: 0.013148, gan: 0.002296), \n",
      "\t\t\t disc_loss = 0.0023 \t(real: 0.000596, fake: 0.001752)\n",
      "\n",
      "Epoch [7] (2400/2500), \t gen_loss  = 0.0178 \t(recr: 0.014973, gan: 0.002788), \n",
      "\t\t\t disc_loss = 0.0024 \t(real: 0.001573, fake: 0.000819)\n",
      "\n",
      "Epoch [7] (2450/2500), \t gen_loss  = 0.0169 \t(recr: 0.014246, gan: 0.002644), \n",
      "\t\t\t disc_loss = 0.0015 \t(real: 0.000733, fake: 0.000735)\n",
      "\n",
      "Epoch [7] done                                 \n",
      "Epoch [8] (0/2500), \t gen_loss  = 0.0181 \t(recr: 0.014396, gan: 0.003660), \n",
      "\t\t\t disc_loss = 0.0015 \t(real: 0.001461, fake: 0.000079)\n",
      "\n",
      "Epoch [8] (50/2500), \t gen_loss  = 0.0170 \t(recr: 0.014498, gan: 0.002544), \n",
      "\t\t\t disc_loss = 0.0030 \t(real: 0.000595, fake: 0.002449)\n",
      "\n",
      "Epoch [8] (100/2500), \t gen_loss  = 0.0179 \t(recr: 0.014482, gan: 0.003452), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000600, fake: 0.000158)\n",
      "\n",
      "Epoch [8] (150/2500), \t gen_loss  = 0.0171 \t(recr: 0.015193, gan: 0.001951), \n",
      "\t\t\t disc_loss = 0.0074 \t(real: 0.000787, fake: 0.006603)\n",
      "\n",
      "Epoch [8] (200/2500), \t gen_loss  = 0.0180 \t(recr: 0.014508, gan: 0.003528), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000502, fake: 0.000285)\n",
      "\n",
      "Epoch [8] (250/2500), \t gen_loss  = 0.0177 \t(recr: 0.015365, gan: 0.002363), \n",
      "\t\t\t disc_loss = 0.0087 \t(real: 0.001871, fake: 0.006822)\n",
      "\n",
      "Epoch [8] (300/2500), \t gen_loss  = 0.0189 \t(recr: 0.016235, gan: 0.002699), \n",
      "\t\t\t disc_loss = 0.0014 \t(real: 0.000632, fake: 0.000796)\n",
      "\n",
      "Epoch [8] (350/2500), \t gen_loss  = 0.0175 \t(recr: 0.015455, gan: 0.002064), \n",
      "\t\t\t disc_loss = 0.0047 \t(real: 0.001005, fake: 0.003734)\n",
      "\n",
      "Epoch [8] (400/2500), \t gen_loss  = 0.0184 \t(recr: 0.014850, gan: 0.003510), \n",
      "\t\t\t disc_loss = 0.0007 \t(real: 0.000568, fake: 0.000108)\n",
      "\n",
      "Epoch [8] (450/2500), \t gen_loss  = 0.0192 \t(recr: 0.015585, gan: 0.003573), \n",
      "\t\t\t disc_loss = 0.0024 \t(real: 0.002053, fake: 0.000352)\n",
      "\n",
      "Epoch [8] (500/2500), \t gen_loss  = 0.0168 \t(recr: 0.015529, gan: 0.001227), \n",
      "\t\t\t disc_loss = 0.9695 \t(real: 0.003547, fake: 0.965957)\n",
      "\n",
      "Epoch [8] (550/2500), \t gen_loss  = 0.0180 \t(recr: 0.015689, gan: 0.002317), \n",
      "\t\t\t disc_loss = 0.0305 \t(real: 0.024964, fake: 0.005561)\n",
      "\n",
      "Epoch [8] (600/2500), \t gen_loss  = 0.0182 \t(recr: 0.016229, gan: 0.001972), \n",
      "\t\t\t disc_loss = 0.0213 \t(real: 0.013379, fake: 0.007960)\n",
      "\n",
      "Epoch [8] (650/2500), \t gen_loss  = 0.0184 \t(recr: 0.016151, gan: 0.002247), \n",
      "\t\t\t disc_loss = 0.0099 \t(real: 0.007900, fake: 0.002016)\n",
      "\n",
      "Epoch [8] (700/2500), \t gen_loss  = 0.0170 \t(recr: 0.013557, gan: 0.003404), \n",
      "\t\t\t disc_loss = 0.0017 \t(real: 0.000976, fake: 0.000749)\n",
      "\n",
      "Epoch [8] (750/2500), \t gen_loss  = 0.0157 \t(recr: 0.013189, gan: 0.002546), \n",
      "\t\t\t disc_loss = 0.0034 \t(real: 0.000338, fake: 0.003019)\n",
      "\n",
      "Epoch [8] (800/2500), \t gen_loss  = 0.0161 \t(recr: 0.013517, gan: 0.002565), \n",
      "\t\t\t disc_loss = 0.0024 \t(real: 0.000191, fake: 0.002173)\n",
      "\n",
      "Epoch [8] (850/2500), \t gen_loss  = 0.0170 \t(recr: 0.014313, gan: 0.002699), \n",
      "\t\t\t disc_loss = 0.0014 \t(real: 0.000314, fake: 0.001130)\n",
      "\n",
      "Epoch [8] (900/2500), \t gen_loss  = 0.0170 \t(recr: 0.014339, gan: 0.002692), \n",
      "\t\t\t disc_loss = 0.0022 \t(real: 0.000357, fake: 0.001802)\n",
      "\n",
      "Epoch [8] (950/2500), \t gen_loss  = 0.0154 \t(recr: 0.012721, gan: 0.002678), \n",
      "\t\t\t disc_loss = 0.0021 \t(real: 0.000229, fake: 0.001897)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8] (1000/2500), \t gen_loss  = 0.0174 \t(recr: 0.014669, gan: 0.002758), \n",
      "\t\t\t disc_loss = 0.0022 \t(real: 0.000725, fake: 0.001481)\n",
      "\n",
      "Epoch [8] (1050/2500), \t gen_loss  = 0.0161 \t(recr: 0.013410, gan: 0.002681), \n",
      "\t\t\t disc_loss = 0.0017 \t(real: 0.000260, fake: 0.001465)\n",
      "\n",
      "Epoch [8] (1100/2500), \t gen_loss  = 0.0170 \t(recr: 0.014327, gan: 0.002700), \n",
      "\t\t\t disc_loss = 0.0020 \t(real: 0.000675, fake: 0.001347)\n",
      "\n",
      "Epoch [8] (1150/2500), \t gen_loss  = 0.0174 \t(recr: 0.014568, gan: 0.002813), \n",
      "\t\t\t disc_loss = 0.0010 \t(real: 0.000413, fake: 0.000632)\n",
      "\n",
      "Epoch [8] (1200/2500), \t gen_loss  = 0.0164 \t(recr: 0.013724, gan: 0.002631), \n",
      "\t\t\t disc_loss = 0.0016 \t(real: 0.000295, fake: 0.001299)\n",
      "\n",
      "Epoch [8] (1250/2500), \t gen_loss  = 0.0172 \t(recr: 0.014550, gan: 0.002601), \n",
      "\t\t\t disc_loss = 0.0015 \t(real: 0.000334, fake: 0.001182)\n",
      "\n",
      "Epoch [8] (1300/2500), \t gen_loss  = 0.0177 \t(recr: 0.014858, gan: 0.002827), \n",
      "\t\t\t disc_loss = 0.0016 \t(real: 0.001081, fake: 0.000548)\n",
      "\n",
      "Epoch [8] (1350/2500), \t gen_loss  = 0.0158 \t(recr: 0.013021, gan: 0.002778), \n",
      "\t\t\t disc_loss = 0.0007 \t(real: 0.000121, fake: 0.000564)\n",
      "\n",
      "Epoch [8] (1400/2500), \t gen_loss  = 0.0175 \t(recr: 0.014744, gan: 0.002748), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000178, fake: 0.000438)\n",
      "\n",
      "Epoch [8] (1450/2500), \t gen_loss  = 0.0169 \t(recr: 0.014254, gan: 0.002666), \n",
      "\t\t\t disc_loss = 0.0013 \t(real: 0.000651, fake: 0.000619)\n",
      "\n",
      "Epoch [8] (1500/2500), \t gen_loss  = 0.0168 \t(recr: 0.014111, gan: 0.002736), \n",
      "\t\t\t disc_loss = 0.0012 \t(real: 0.000821, fake: 0.000405)\n",
      "\n",
      "Epoch [8] (1550/2500), \t gen_loss  = 0.0175 \t(recr: 0.014774, gan: 0.002744), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000268, fake: 0.000325)\n",
      "\n",
      "Epoch [8] (1600/2500), \t gen_loss  = 0.0165 \t(recr: 0.013798, gan: 0.002668), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000092, fake: 0.000394)\n",
      "\n",
      "Epoch [8] (1650/2500), \t gen_loss  = 0.0166 \t(recr: 0.013977, gan: 0.002649), \n",
      "\t\t\t disc_loss = 0.0007 \t(real: 0.000137, fake: 0.000516)\n",
      "\n",
      "Epoch [8] (1700/2500), \t gen_loss  = 0.0166 \t(recr: 0.014192, gan: 0.002434), \n",
      "\t\t\t disc_loss = 0.0013 \t(real: 0.000273, fake: 0.000991)\n",
      "\n",
      "Epoch [8] (1750/2500), \t gen_loss  = 0.0173 \t(recr: 0.014405, gan: 0.002912), \n",
      "\t\t\t disc_loss = 0.0008 \t(real: 0.000531, fake: 0.000252)\n",
      "\n",
      "Epoch [8] (1800/2500), \t gen_loss  = 0.0171 \t(recr: 0.014457, gan: 0.002631), \n",
      "\t\t\t disc_loss = 0.0007 \t(real: 0.000123, fake: 0.000548)\n",
      "\n",
      "Epoch [8] (1850/2500), \t gen_loss  = 0.0163 \t(recr: 0.013593, gan: 0.002678), \n",
      "\t\t\t disc_loss = 0.0007 \t(real: 0.000207, fake: 0.000466)\n",
      "\n",
      "Epoch [8] (1900/2500), \t gen_loss  = 0.0177 \t(recr: 0.014933, gan: 0.002815), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000177, fake: 0.000393)\n",
      "\n",
      "Epoch [8] (1950/2500), \t gen_loss  = 0.0179 \t(recr: 0.014915, gan: 0.003001), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000209, fake: 0.000220)\n",
      "\n",
      "Epoch [8] (2000/2500), \t gen_loss  = 0.0167 \t(recr: 0.013986, gan: 0.002762), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000114, fake: 0.000366)\n",
      "\n",
      "Epoch [8] (2050/2500), \t gen_loss  = 0.0174 \t(recr: 0.014658, gan: 0.002699), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000255, fake: 0.000395)\n",
      "\n",
      "Epoch [8] (2100/2500), \t gen_loss  = 0.0176 \t(recr: 0.014799, gan: 0.002795), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000171, fake: 0.000306)\n",
      "\n",
      "Epoch [8] (2150/2500), \t gen_loss  = 0.0171 \t(recr: 0.014385, gan: 0.002738), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000123, fake: 0.000337)\n",
      "\n",
      "Epoch [8] (2200/2500), \t gen_loss  = 0.0175 \t(recr: 0.014525, gan: 0.003017), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000092, fake: 0.000141)\n",
      "\n",
      "Epoch [8] (2250/2500), \t gen_loss  = 0.0178 \t(recr: 0.014889, gan: 0.002882), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000068, fake: 0.000338)\n",
      "\n",
      "Epoch [8] (2300/2500), \t gen_loss  = 0.0168 \t(recr: 0.013737, gan: 0.003060), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000118, fake: 0.000149)\n",
      "\n",
      "Epoch [8] (2350/2500), \t gen_loss  = 0.0176 \t(recr: 0.014718, gan: 0.002872), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000127, fake: 0.000251)\n",
      "\n",
      "Epoch [8] (2400/2500), \t gen_loss  = 0.0169 \t(recr: 0.014112, gan: 0.002749), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000085, fake: 0.000287)\n",
      "\n",
      "Epoch [8] (2450/2500), \t gen_loss  = 0.0168 \t(recr: 0.014015, gan: 0.002822), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000083, fake: 0.000199)\n",
      "\n",
      "Epoch [8] done                                 \n",
      "Epoch [9] (0/2500), \t gen_loss  = 0.0173 \t(recr: 0.014196, gan: 0.003100), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000172, fake: 0.000085)\n",
      "\n",
      "Epoch [9] (50/2500), \t gen_loss  = 0.0185 \t(recr: 0.015541, gan: 0.002943), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000351, fake: 0.000167)\n",
      "\n",
      "Epoch [9] (100/2500), \t gen_loss  = 0.0174 \t(recr: 0.014744, gan: 0.002663), \n",
      "\t\t\t disc_loss = 0.0010 \t(real: 0.000097, fake: 0.000869)\n",
      "\n",
      "Epoch [9] (150/2500), \t gen_loss  = 0.0166 \t(recr: 0.013531, gan: 0.003048), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000102, fake: 0.000152)\n",
      "\n",
      "Epoch [9] (200/2500), \t gen_loss  = 0.0179 \t(recr: 0.014881, gan: 0.002999), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000118, fake: 0.000241)\n",
      "\n",
      "Epoch [9] (250/2500), \t gen_loss  = 0.0180 \t(recr: 0.014893, gan: 0.003059), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000153, fake: 0.000117)\n",
      "\n",
      "Epoch [9] (300/2500), \t gen_loss  = 0.0174 \t(recr: 0.014380, gan: 0.003056), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000171, fake: 0.000115)\n",
      "\n",
      "Epoch [9] (350/2500), \t gen_loss  = 0.0170 \t(recr: 0.014384, gan: 0.002589), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000244, fake: 0.000403)\n",
      "\n",
      "Epoch [9] (400/2500), \t gen_loss  = 0.0176 \t(recr: 0.014686, gan: 0.002931), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000078, fake: 0.000482)\n",
      "\n",
      "Epoch [9] (450/2500), \t gen_loss  = 0.0177 \t(recr: 0.014965, gan: 0.002718), \n",
      "\t\t\t disc_loss = 0.0007 \t(real: 0.000132, fake: 0.000588)\n",
      "\n",
      "Epoch [9] (500/2500), \t gen_loss  = 0.0169 \t(recr: 0.014074, gan: 0.002801), \n",
      "\t\t\t disc_loss = 0.0006 \t(real: 0.000172, fake: 0.000384)\n",
      "\n",
      "Epoch [9] (550/2500), \t gen_loss  = 0.0170 \t(recr: 0.013910, gan: 0.003079), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000103, fake: 0.000149)\n",
      "\n",
      "Epoch [9] (600/2500), \t gen_loss  = 0.0179 \t(recr: 0.015049, gan: 0.002841), \n",
      "\t\t\t disc_loss = 0.0005 \t(real: 0.000109, fake: 0.000376)\n",
      "\n",
      "Epoch [9] (650/2500), \t gen_loss  = 0.0194 \t(recr: 0.016748, gan: 0.002612), \n",
      "\t\t\t disc_loss = 0.0010 \t(real: 0.000134, fake: 0.000894)\n",
      "\n",
      "Epoch [9] (700/2500), \t gen_loss  = 0.0173 \t(recr: 0.013719, gan: 0.003602), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000135, fake: 0.000203)\n",
      "\n",
      "Epoch [9] (750/2500), \t gen_loss  = 0.0173 \t(recr: 0.013987, gan: 0.003355), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000097, fake: 0.000255)\n",
      "\n",
      "Epoch [9] (800/2500), \t gen_loss  = 0.0179 \t(recr: 0.014527, gan: 0.003411), \n",
      "\t\t\t disc_loss = 0.0004 \t(real: 0.000080, fake: 0.000344)\n",
      "\n",
      "Epoch [9] (850/2500), \t gen_loss  = 0.0173 \t(recr: 0.013949, gan: 0.003371), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000065, fake: 0.000101)\n",
      "\n",
      "Epoch [9] (900/2500), \t gen_loss  = 0.0170 \t(recr: 0.013689, gan: 0.003279), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000110, fake: 0.000193)\n",
      "\n",
      "Epoch [9] (950/2500), \t gen_loss  = 0.0167 \t(recr: 0.013396, gan: 0.003309), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000053, fake: 0.000115)\n",
      "\n",
      "Epoch [9] (1000/2500), \t gen_loss  = 0.0175 \t(recr: 0.014112, gan: 0.003347), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000127, fake: 0.000110)\n",
      "\n",
      "Epoch [9] (1050/2500), \t gen_loss  = 0.0166 \t(recr: 0.013419, gan: 0.003216), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000054, fake: 0.000133)\n",
      "\n",
      "Epoch [9] (1100/2500), \t gen_loss  = 0.0156 \t(recr: 0.012329, gan: 0.003227), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000067, fake: 0.000123)\n",
      "\n",
      "Epoch [9] (1150/2500), \t gen_loss  = 0.0170 \t(recr: 0.013731, gan: 0.003249), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000034, fake: 0.000125)\n",
      "\n",
      "Epoch [9] (1200/2500), \t gen_loss  = 0.0168 \t(recr: 0.013576, gan: 0.003218), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000041, fake: 0.000106)\n",
      "\n",
      "Epoch [9] (1250/2500), \t gen_loss  = 0.0168 \t(recr: 0.013596, gan: 0.003228), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000032, fake: 0.000154)\n",
      "\n",
      "Epoch [9] (1300/2500), \t gen_loss  = 0.0170 \t(recr: 0.013891, gan: 0.003119), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000056, fake: 0.000131)\n",
      "\n",
      "Epoch [9] (1350/2500), \t gen_loss  = 0.0169 \t(recr: 0.013792, gan: 0.003137), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000048, fake: 0.000186)\n",
      "\n",
      "Epoch [9] (1400/2500), \t gen_loss  = 0.0179 \t(recr: 0.014778, gan: 0.003131), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000063, fake: 0.000154)\n",
      "\n",
      "Epoch [9] (1450/2500), \t gen_loss  = 0.0173 \t(recr: 0.014002, gan: 0.003250), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000050, fake: 0.000151)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9] (1500/2500), \t gen_loss  = 0.0168 \t(recr: 0.013633, gan: 0.003127), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000069, fake: 0.000133)\n",
      "\n",
      "Epoch [9] (1550/2500), \t gen_loss  = 0.0162 \t(recr: 0.013081, gan: 0.003096), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000042, fake: 0.000123)\n",
      "\n",
      "Epoch [9] (1600/2500), \t gen_loss  = 0.0167 \t(recr: 0.013523, gan: 0.003171), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000051, fake: 0.000156)\n",
      "\n",
      "Epoch [9] (1650/2500), \t gen_loss  = 0.0165 \t(recr: 0.013216, gan: 0.003283), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000036, fake: 0.000087)\n",
      "\n",
      "Epoch [9] (1700/2500), \t gen_loss  = 0.0171 \t(recr: 0.013866, gan: 0.003215), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000060, fake: 0.000105)\n",
      "\n",
      "Epoch [9] (1750/2500), \t gen_loss  = 0.0167 \t(recr: 0.013489, gan: 0.003218), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000064, fake: 0.000102)\n",
      "\n",
      "Epoch [9] (1800/2500), \t gen_loss  = 0.0171 \t(recr: 0.013875, gan: 0.003243), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000039, fake: 0.000074)\n",
      "\n",
      "Epoch [9] (1850/2500), \t gen_loss  = 0.0172 \t(recr: 0.013905, gan: 0.003333), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000073, fake: 0.000053)\n",
      "\n",
      "Epoch [9] (1900/2500), \t gen_loss  = 0.0172 \t(recr: 0.014052, gan: 0.003175), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000038, fake: 0.000097)\n",
      "\n",
      "Epoch [9] (1950/2500), \t gen_loss  = 0.0161 \t(recr: 0.012866, gan: 0.003280), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000057, fake: 0.000064)\n",
      "\n",
      "Epoch [9] (2000/2500), \t gen_loss  = 0.0167 \t(recr: 0.013486, gan: 0.003262), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000059, fake: 0.000062)\n",
      "\n",
      "Epoch [9] (2050/2500), \t gen_loss  = 0.0172 \t(recr: 0.013969, gan: 0.003245), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000096, fake: 0.000068)\n",
      "\n",
      "Epoch [9] (2100/2500), \t gen_loss  = 0.0167 \t(recr: 0.013417, gan: 0.003256), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000033, fake: 0.000064)\n",
      "\n",
      "Epoch [9] (2150/2500), \t gen_loss  = 0.0163 \t(recr: 0.012943, gan: 0.003332), \n",
      "\t\t\t disc_loss = 0.0003 \t(real: 0.000223, fake: 0.000048)\n",
      "\n",
      "Epoch [9] (2200/2500), \t gen_loss  = 0.0174 \t(recr: 0.014106, gan: 0.003274), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000129, fake: 0.000061)\n",
      "\n",
      "Epoch [9] (2250/2500), \t gen_loss  = 0.0168 \t(recr: 0.013516, gan: 0.003297), \n",
      "\t\t\t disc_loss = 0.0002 \t(real: 0.000162, fake: 0.000059)\n",
      "\n",
      "Epoch [9] (2300/2500), \t gen_loss  = 0.0167 \t(recr: 0.013405, gan: 0.003296), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000045, fake: 0.000049)\n",
      "\n",
      "Epoch [9] (2350/2500), \t gen_loss  = 0.0172 \t(recr: 0.013848, gan: 0.003311), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000049, fake: 0.000056)\n",
      "\n",
      "Epoch [9] (2400/2500), \t gen_loss  = 0.0157 \t(recr: 0.012444, gan: 0.003260), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000041, fake: 0.000069)\n",
      "\n",
      "Epoch [9] (2450/2500), \t gen_loss  = 0.0172 \t(recr: 0.013859, gan: 0.003314), \n",
      "\t\t\t disc_loss = 0.0001 \t(real: 0.000046, fake: 0.000048)\n",
      "\n",
      "Epoch [9] done                                 \n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_loader, verbose=True, epochs=10, print_every=50)\n",
    "trainer.save_data(force_save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5188626cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f51886e4390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_lstm_eval_2(gen, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
